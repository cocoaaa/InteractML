{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified: Jul 17, 2019\n",
    "# Curve Representation using Levelset function\n",
    "- Signed Distance Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, time\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.signal import correlate2d\n",
    "import pandas as pd\n",
    "    \n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "p = print\n",
    "\n",
    "from functools import lru_cache\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "import pdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "# Don't generate bytecode\n",
    "sys.dont_write_bytecode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import xarray as xr\n",
    "\n",
    "from holoviews import opts, dim\n",
    "from holoviews.operation.datashader import datashade, shade, dynspread, rasterize\n",
    "from holoviews.streams import Stream, param\n",
    "from holoviews import streams\n",
    "\n",
    "\n",
    "import panel as pn\n",
    "from bokeh.palettes import GnBu9\n",
    "\n",
    "\n",
    "hv.notebook_extension('bokeh')\n",
    "hv.Dimension.type_formatters[np.datetime64] = '%Y-%m-%d'\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the utils directory to the search path\n",
    "UTILS_DIR = Path('../utils').absolute()\n",
    "assert UTILS_DIR.exists()\n",
    "if str(UTILS_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(UTILS_DIR))\n",
    "    print(f\"Added {str(UTILS_DIR)} to sys.path\")\n",
    "\n",
    "# pp(sys.path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_mro as mro, nprint, timeit\n",
    "import utils as u\n",
    "\n",
    "import sdfs \n",
    "from vector import Vector as vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set visualization options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = 500,500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%opts Image [colorbar=True, active_tools=['wheel_zoom'], tools=['hover']] Curve [tools=['hover'], active_tools=['wheel_zoom']] RGB [active_tools=['wheel_zoom'], tools=['hover']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_opts = opts.Image(height=H, width=W)\n",
    "vfield_opts = opts.VectorField(width=W, height=H, color='Magnitude',\n",
    "#                                magnitude=dim('Magnitude').norm()*0.2,\n",
    "                               pivot='tip',\n",
    "                               rescale_lengths=True)\n",
    "curve_opts = opts.Points(size=5,width=W, height=H, padding=0.1, \n",
    "#                             xlim=(-10,10), ylim=(-10,10),\n",
    "#                         color=dim('p')*256-50\n",
    "                        )\n",
    "contour_opts = opts.Contours(width=W, height=H, \n",
    "                             colorbar=False,\n",
    "                             legend_position='bottom',\n",
    "                             tools=['hover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab registered bokeh renderer\n",
    "print(\"Currently available renderers: \", *hv.Store.renderers.keys())\n",
    "renderer = hv.renderer('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamz\n",
    "import streamz.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deinf a curve on a plane (ie. planary curve) we need\n",
    "- parameter, eg. p $\\in [0,1]$\n",
    "- two functions $x(p)$ and $y(p)$, which define the coordinate of the point $C(p)$ in x and y axis, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signed Distance Function \n",
    "### For a circle\n",
    "\n",
    "- $\\phi(x,y)$ is the distance between point $p = (x,y)$ and the curve. Here the curve we want to represent is a unit circle\n",
    "- $\\phi(x,y)$ is Dist(origin, $p$) - Dist(origin, a point on the unit circle touched by a stright ray passing through the origin and $p$). The second term is always 1 for a unit circle. So we get the $\\phi$ as following:\n",
    "\n",
    "$ \\phi(x,y) = \\sqrt{(x^2+y^2)} - 1 $\n",
    "\n",
    "Now let's visualize it using holoviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(x,y):\n",
    "    \"\"\"Signed Distance function for a unit circle\"\"\"\n",
    "    return np.sqrt(x**2 + y**2) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "xs = np.linspace(-1.5,1.5,num=n)\n",
    "ys = np.linspace(-1.5,1.5,num=n)[::-1] #flipped because I'm interested in the cartesian coordinate system's view\n",
    "# nprint(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = np.meshgrid(xs,ys)\n",
    "Z = phi(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See hv.Image?\n",
    "cmap = ['twilight', 'RdBu','Spectral']\n",
    "img = hv.Image((xs,ys,Z)).opts(img_opts).opts(cmap=cmap[1])\n",
    "contour = hv.operation.contours(img, levels=1).opts(contour_opts).opts(cmap='gray') #love this level=0:D\n",
    "img * contour\n",
    "#or, equivalently hv.Image(Z, bounds=(xs.min(), ys.min(), xs.max(), ys.max())).opts(img_opts)#.opts(cmap='twilight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[-0.5,0,0.5]])\n",
    "corr_opts = dict(mode='same')\n",
    "Zx = correlate2d(Z,kernel, **corr_opts)\n",
    "Zy= correlate2d(Z, kernel.T, **corr_opts)\n",
    "\n",
    "(\n",
    "    hv.Image((xs,ys,Zx)) + hv.Image((xs,ys,Zy))\n",
    ").opts(img_opts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_contour(xs, ys, Z, cmap=None, show_contour=True, levels=1):\n",
    "    if cmap is None:\n",
    "        cmap=dict(img_cmap='RdBu', contour_cmap='gray')\n",
    "    img = hv.Image((xs,ys,Z)).opts(img_opts).opts(cmap=cmap['img_cmap'])\n",
    "    contour = hv.operation.contours(img, levels=levels).opts(contour_opts).opts(cmap=cmap['contour_cmap']) #love this level=0:D\n",
    "    if show_contour:\n",
    "        return img*contour\n",
    "    return img\n",
    "\n",
    "def UV2angMag(U,V):\n",
    "    \"\"\"\n",
    "    U,V (MxN np.ndarray): encodes X,Y coordinate grids respectively\n",
    "    Returns:\n",
    "    - angle, mag: tuple of MxN np.ndarray that encode ang (or mag) for the grid space\n",
    "    That means, angle[j][i] at (X[j][i],Y[j][i]) location\n",
    "    \"\"\"\n",
    "    mag = np.sqrt(U**2 + V**2)\n",
    "    angle = (np.pi/2.) - np.arctan2(U/mag, V/mag)\n",
    "#     angle =  np.arctan2(V,U)\n",
    "\n",
    "\n",
    "    return (angle, mag)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_contour(xs,ys,Zx)+ img_contour(xs,ys,Zy)#,show_contour=False, levels=5)\n",
    "grad_angle, grad_mag = UV2angMag(Zx,Zy)\n",
    "gradfield = hv.VectorField( (X,Y,grad_angle, grad_mag) ).opts(vfield_opts)#.opts(height=1000, width=1000)\n",
    "\n",
    "# img.opts(height=1000,width=1000) * contour * gradfield\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Modified: Jul 21, 2019\n",
    "\n",
    "## Curve Evolution \n",
    "- [ ] Finite Difference method on parametric equations\n",
    "- [ ] Levelset functions\n",
    "    - 2D signed distance functions: [src](https://is.gd/t7p5mk)\n",
    "- [ ] Active contour on satellite images\n",
    "- [ ] Agent-based modelling with specified rules\n",
    "    - satellite image segmentation (~ clustering based on local features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sdf(xs, ys, sdFunc):\n",
    "    zz = np.empty( (len(ys), len(xs)) )\n",
    "    \n",
    "    for j in range(len(ys)):\n",
    "        for i in range(len(xs)):\n",
    "            q = vec(xs[i],ys[j])\n",
    "            zz[j,i] = sdFunc(q)\n",
    "    return zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE = {}\n",
    "HITS = defaultdict(int)\n",
    "\n",
    "t = 0\n",
    "xrange = (-1,1)\n",
    "yrange=(-1,1)\n",
    "n_points = 100\n",
    "xs = np.linspace(*xrange,num=n_points)\n",
    "ys = np.linspace(*yrange,num=n_points)\n",
    "\n",
    "sdf = sdfs.sdUnitCircle\n",
    "key = str((xrange, yrange, n_points, sdf))\n",
    "\n",
    "try:\n",
    "    zz = CACHE[key]\n",
    "    HITS[key] += 1\n",
    "\n",
    "except KeyError:\n",
    "    zz = eval_sdf(xs, ys, sdf)\n",
    "    CACHE[key] = zz\n",
    "\n",
    "zz0_img = hv.Image( (xs, ys, zz), group='zz', label='t0' ).opts(img_opts)\\\n",
    "            .opts(xlim=xrange, ylim=yrange)\n",
    "zz0_contour = hv.operation.contours(zz_img, levels=0, group='contour').opts(contour_opts) \\\n",
    "            .opts(xlim=xrange, ylim=yrange, cmap='gray')\n",
    "\n",
    "# compute gradients\n",
    "gradx = correlate2d(zz, kernel, mode='same')\n",
    "grady = correlate2d(zz, kernel.T, mode='same')\n",
    "\n",
    "ang, mag = u.UV2angMag(gradx, grady)\n",
    "\n",
    "gradfield = hv.VectorField((xs, ys, ang, mag)).opts(vfield_opts)\n",
    "gradmag_img = hv.Image( (xs,ys,np.abs(mag)), group='grad', label='t0' ).opts(img_opts).opts(xlim=xrange, ylim=yrange)\n",
    "\n",
    "overlay = datashade(zz0_img, cmap=GnBu9) * zz0_contour * gradfield + gradmag_img\n",
    "\n",
    "# overlay\n",
    "img0 = zz0_img *zz0_contour \n",
    "grad0 = gradmag_img * zz0_contour\n",
    "img0+grad0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz1 = zz - np.abs(mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz1_img = hv.Image( (xs,ys,zz1), group='zz', label='t1' ).opts(img_opts).opts(xlim=xrange, ylim=yrange)\n",
    "zz1_contour = hv.operation.contours(zz1_img, levels=0, group='contour').opts(contour_opts) \\\n",
    "            .opts(xlim=xrange, ylim=yrange, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = zz1_img *zz1_contour\n",
    "(img0 + img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.NdOverlay({1:zz0_contour, 2:zz1_contour})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step function to evolve the levelset equation for curve \n",
    "General curve evolution can be simulated as time integration process of the solving the following `initial value problem` for a general PDE:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\phi}{\\partial t} = L(t, \\phi(t)), ~~~~ \\phi(t_0) = \\phi^{0}\n",
    "$$\n",
    "\n",
    "Note that we will use $\\frac{\\partial \\phi}{\\partial t}$ and $\\phi_t$ interchangably, to denote the time derivative of $\\phi$.\n",
    "\n",
    "\n",
    "The first-order Taylor expansion about $(t+\\Delta t)$ gives,\n",
    "\n",
    "$$\n",
    "\\phi( t+\\Delta t) \\approx \\phi(t) + \\Delta t \\phi_{t}(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the [CFL](#) condition, if $L$ depends on at most the first-order derivatives (eg. $\\nabla \\phi$, the spatial derivative of $\\phi$), then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's implement the curve evolution according to this PDE:\n",
    "\n",
    "$$\n",
    "\\phi_{t}(x,y,t) = \\lVert \\nabla \\phi(x,y,t) \\rVert\n",
    "$$\n",
    "\n",
    "1. Inputs\n",
    "    - phi (MxN) at current time\n",
    "2. Computation\n",
    "    - compute gradx, grady -> mag_grad\n",
    "    - next_phi = phi - abs(mag_grad)\n",
    "        - make hv.image of next_phi\n",
    "        - make hv.contour of next_phi\n",
    "        - save the contour into a list\n",
    "    - after all iterations, make ndOverlay from the list of contours -> thish will show the unit circle's evolution according to:\n",
    "\n",
    "$$\n",
    "\\phi_{t}(x,y,t) = \\left| \\nabla \\phi(x,y,t) \\right|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(xs, ys, zz, return_grad=True, **kwargs):\n",
    "    \"\"\"\n",
    "    One step of curve evolution of levelset function. \n",
    "    In other words, this function defins a discrete version of PDE for a curve evolution \n",
    "    Returns current zz's gradients and next zz\n",
    "    \n",
    "    Args:\n",
    "    - xs (1D array of length N): x-coordinates\n",
    "    - ys (1D array of length M): y-coordinates\n",
    "    - zz (MxN np.ndarray): values of the levelset function s.t.\n",
    "        zz[j][i] = phi(x=xs[i], y=ys[j])\n",
    "        \n",
    "    - kwargs (dict) may have the following (key, value) pairs:\n",
    "        - \"step_idx\" -> (int) : indicating the iteration index following the (discreate) curve evolution equation\n",
    "    \n",
    "    Returns:\n",
    "    - a tuple of MxN np.ndarray(s): \n",
    "        If return_grad is True, returns (grad_ang, grad_mag, next_zz), or (next_zz)\n",
    "        where next_zz encodes the levelset values after a single step of curve evolution\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute gradients\n",
    "    gradx = correlate2d(zz, kernel, mode='same')\n",
    "    grady = correlate2d(zz, kernel.T, mode='same')\n",
    "\n",
    "    grad_ang, grad_mag = u.UV2angMag(gradx, grady)\n",
    "    next_zz = zz - np.abs(grad_mag)\n",
    "    if return_grad:\n",
    "        return (grad_ang, grad_mag, next_zz)\n",
    "    else:\n",
    "        return (next_zz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize curve evolution\n",
    "## First, define xs, ys ,and initial zz\n",
    "CACHE = {}\n",
    "HITS = defaultdict(int)\n",
    "\n",
    "xrange = (-1,1)\n",
    "yrange=(-1,1)\n",
    "n_points = 100\n",
    "xs = np.linspace(*xrange,num=n_points)\n",
    "ys = np.linspace(*yrange,num=n_points)\n",
    "\n",
    "# sdf = sdfs.sdUnitCircle\n",
    "sdf = sdfs.sdUnitHline\n",
    "\n",
    "zz = eval_sdf(xs, ys, sdf)\n",
    "\n",
    "n_steps = 10\n",
    "step_idx = 0\n",
    "\n",
    "contours = {}\n",
    "\n",
    "cmaps_filtered = ['Reds','Oranges', 'YlOrRd', 'Greens', 'Blues', 'PuBuGn', 'PuRd', 'Purples', 'Greys']\n",
    "while step_idx < n_steps:\n",
    "    zz_img = hv.Image( (xs, ys, zz), group=f'{step_idx}' ).opts(img_opts) \\\n",
    "                .opts(xlim=xrange, ylim=yrange)\n",
    "    zz_contour = hv.operation.contours(zz_img, levels=0).relabel(group=f'{step_idx}').opts(contour_opts) \\\n",
    "                .opts(xlim=xrange, ylim=yrange, cmap=cmaps_filtered[step_idx%len(cmaps_filtered)])\n",
    "\n",
    "    contours[step_idx] = zz_contour\n",
    "\n",
    "    # get current gradients and update levelset to next step\n",
    "    grad_ang, grad_mag, next_zz = step(xs, ys, zz)\n",
    "    gradfield = hv.VectorField((xs, ys, grad_ang, grad_mag), group=f'{step_idx}').opts(vfield_opts)\n",
    "\n",
    "    zz = next_zz\n",
    "    step_idx += 1\n",
    "nd_contours = hv.NdOverlay(contours, group='Contours', kdims='step')#.opts(hv.opts('Contours', color='step'))\n",
    "nd_contours;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take 2: Better coloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize curve evolution\n",
    "## First, define xs, ys ,and initial zz\n",
    "CACHE = {}\n",
    "HITS = defaultdict(int)\n",
    "\n",
    "xrange = (-5,5)\n",
    "yrange=(-5,5)\n",
    "n_points = 100\n",
    "xs = np.linspace(*xrange,num=n_points)\n",
    "ys = np.linspace(*yrange,num=n_points)\n",
    "\n",
    "# sdf = sdfs.sdUnitCircle\n",
    "sdf = sdfs.sdUnitHline\n",
    "zz = eval_sdf(xs, ys, sdf)\n",
    "\n",
    "n_steps = 20\n",
    "step_idx = 0\n",
    "\n",
    "contours = {}\n",
    "while step_idx < n_steps:\n",
    "    zz_img = hv.Image( (xs, ys, zz), group=f'{step_idx}' ).opts(img_opts) \\\n",
    "                .opts(xlim=xrange, ylim=yrange)\n",
    "    zz_contour = hv.operation.contours(zz_img, levels=0).relabel(group=f'{step_idx}').opts(contour_opts) \\\n",
    "                .opts(xlim=xrange, ylim=yrange)\n",
    "\n",
    "    contours[step_idx] = zz_contour\n",
    "\n",
    "    # get current gradients and update levelset to next step\n",
    "    grad_ang, grad_mag, next_zz = step(xs, ys, zz)\n",
    "    gradfield = hv.VectorField((xs, ys, grad_ang, grad_mag), group=f'{step_idx}').opts(vfield_opts)\n",
    "\n",
    "    zz = next_zz\n",
    "    step_idx += 1\n",
    "\n",
    "\n",
    "# Put each (single-layer) contour line together into a single contours element\n",
    "all_contours = hv.Contours([contour.add_dimension('step', 1, i, vdim=True) \n",
    "                            for i, contour in contours.items()], vdims=['z', 'step']).opts(contour_opts) \n",
    "all_contours.opts(cmap='Greens_r',color='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Ramesh-X/ModelViewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Please refer to this [thesis](#) for more details\n",
    "\n",
    "## Fundamental level-set equations\n",
    " \n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\phi}{\\partial{t}} &= -\\nabla{\\phi} \\cdot \\vec{V}  \\label{eq:4.7}  \\tag{4.7} \\\\\n",
    "                                  &= \\lVert \\vec{\\nabla} \\phi \\rVert F(\\vec{x}, \\vec{n}, \\phi, ... )\n",
    "                                     \\label{eq:4.8}  \\tag{4.8} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Key:\n",
    "- $Eqn. \\ref{eq:4.7}$: describes the transportation of the interface (ie. curve) in an external vector field\n",
    "- $Eqn. \\ref{eq:4.8}$: describes the motion of the interface in its normal direction by a magnitude determined by the speed function, $F$\n",
    "    - $F = $ const \n",
    "    - $F = - \\alpha \\kappa$ for some $ \\alpha > 0$ \n",
    "\n",
    "\n",
    "## <mark> Stability of the solution </mark> [todo]\n",
    "### 1. Choice of discrete spatial derivative -- forward, backward, central\n",
    "\n",
    "- If the levelset equation depends on at most order 1 derivatives:\n",
    "\n",
    "    For example, \n",
    "    $$\n",
    "    \\begin{align}\n",
    "    F &= 1 \\\\\n",
    "    \\Rightarrow \\frac{\\partial \\phi}{\\partial{t}} &= \\lVert \\vec{\\nabla} \\phi \\rVert\n",
    "    \\end{align}\n",
    "    $$\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "- If the levelset equation depends on derivatives of order $\\geq 2$:\n",
    "\n",
    "    For example, \n",
    "    $$\n",
    "    \\begin{align}\n",
    "    F &= - \\frac{1}{\\lVert \\vec{\\nabla} \\phi \\rVert} \\kappa \\\\\n",
    "    \\Rightarrow \\frac{\\partial \\phi}{\\partial{t}} &=  \\kappa\n",
    "    \\end{align}\n",
    "    $$\n",
    "    Recall that the curvature $\\kappa$ involves second derivatives of $\\phi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective 1: solve \\ref{eq:4.7} as an advection problem\n",
    "- **Advection**: transportation of the interface in an external vector field\n",
    "\n",
    "One way to implement the dynamic curve evolution is to view the curve (or surface in 3D) as a floating object in some flow field $\\vec{V}$ and solve the time integration of an **initial-valued problem** of the following PDE.  In continuous time domain, this is expressed as:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\phi}{\\partial t} = - \\vec{\\nabla} \\phi \\cdot \\vec{V}  \n",
    "$$\n",
    "\n",
    "where the vector $\\vec{\\nabla} \\phi$ refers to the spatial gradient of $\\phi$. Note that a vector normal to any levelset satisfies:\n",
    "\n",
    "$$\\vec{n} = \\frac{\\vec{\\nabla} \\phi}{ \\lVert \\vec{\\nabla} \\phi \\rVert }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, $\\ref{eq:4.7}$ is projecting each flow vector at $(x,y)$ on the grid to $\\vec{n}(x,y)$, which it takes into account just the component of the flow in the direction of the normal. \n",
    "\n",
    "### Up-winding \n",
    "- as a way to choose the correct direction of spatial derivative \n",
    "\n",
    "Let's denote the spatial gradient of $\\phi$ as $\\phi_{\\vec{x}} = (\\phi_x, \\phi_y)$.\n",
    "- The information need to compute the accurate spatial derivatives, $\\phi_x, \\phi_y$, comes from the **reverse direction** of the vector field flow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement discrete gradients \n",
    "Assume the input array is in Cartesian coordinate (rather than image coordinate or numpy array indexing order)\n",
    "\n",
    "- mode: forward, backward, central\n",
    "- axis: 0 (y-axis), 1 (x-axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use scipy `correlated2d`\n",
    "\n",
    "### First, gradient in x direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backwardx_kernel = np.atleast_2d([-1,1,0] )\n",
    "forwardx_kernel = np.atleast_2d([0,-1,1] )\n",
    "# unnecessary operation will be incurred because of the last zero, \n",
    "#but this ensures the center of kernel is overlaid on the location of interest\n",
    "test = np.array( [[1,2,5,10,100], \n",
    "                  [0,-1,10,-3,9],\n",
    "                  [100,-20, 8, 10,-10]]\n",
    "               )\n",
    "gradx_backward = correlate2d(test, backwardx_kernel, mode='same')\n",
    "gradx_forward = correlate2d(test, forwardx_kernel, mode='same')\n",
    "\n",
    "nprint('original', test)\n",
    "nprint('gradx back: ', gradx_backward)\n",
    "nprint('gradx forward: ', gradx_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the top-left element in the backward gradient in x (`gradx back`). Since it corresponds to the location in xy-plane at x=0, there is no previous value to compute its backward difference from. We can handle this case in several different ways:\n",
    "\n",
    "- use the value as is: this is equialent to pad zero as the leftmost column. use boundary='fill' and fillvalue=0\n",
    "- use the forward difference: this is equivalent to use boundary='symm' \n",
    "\n",
    "The first method is what we tried above since it's the default setting of `correlate2d`. Let's check the second method now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradx_backward = correlate2d(test, backwardx_kernel, mode='same', boundary='symm')\n",
    "gradx_forward = correlate2d(test, forwardx_kernel, mode='same', boundary='symm')\n",
    "\n",
    "nprint('original', test)\n",
    "nprint('gradx back: ', gradx_backward)\n",
    "nprint('gradx forward: ', gradx_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, so it seems like 'symm' option actually copies starting as the edge column. This is not the forward difference. With our `backwardx_kernel`, this will always result zero column. So let's instead just replace the first column of the `gradx_backward` with the first column of the `gradx_forward`.  Similarly, we can handle the other edge case (ie. the last column of the output `gradx_forward` where the forward value to take the forward difference with do not exist, by placing it with the backward difference values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backwardx_kernel = np.atleast_2d([-1,1,0] )\n",
    "forwardx_kernel = np.atleast_2d([0,-1,1] )\n",
    "\n",
    "test = np.array( [[1,2,5,10,100], \n",
    "                  [0,-1,10,-3,9],\n",
    "                  [100,-20, 8, 10,-10]]\n",
    "               )\n",
    "dxb = correlate2d(test, backwardx_kernel, mode='same')\n",
    "dxf = correlate2d(test, forwardx_kernel, mode='same')\n",
    "\n",
    "nprint('original', test)\n",
    "nprint('gradx back: ', dxb)\n",
    "nprint('gradx forward: ', dxf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now replace the first column of backwardx with the first column of forwardx \n",
    "# And replace the last column of the forwardx with the last column of backwardx\n",
    "dxb[:,0] = dxf[:,0]\n",
    "dxf[:,-1] = dxb[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backwardx_kernel = np.atleast_2d([-1,1,0] )\n",
    "forwardx_kernel = np.atleast_2d([-1,1] )\n",
    "\n",
    "@timeit\n",
    "def gradx(M, switch):\n",
    "    dxb = correlate2d(test, backwardx_kernel, mode='same')\n",
    "    dxf = correlate2d(test, forwardx_kernel, mode='same')\n",
    "\n",
    "    if switch:\n",
    "        dxb[:,0] = dxf[:,0]\n",
    "        dxf[:,-1] = dxb[:,-1]\n",
    "\n",
    "    return dxb, dxf\n",
    "\n",
    "def test_gradx():\n",
    "    test = np.array( [[1,2,5,10,100], \n",
    "                  [0,-1,10,-3,9],\n",
    "                  [100,-20, 8, 10,-10]]\n",
    "                   )\n",
    "    switch = True\n",
    "    dxb, dxf = gradx(test, switch)\n",
    "    nprint('original', test)\n",
    "    nprint('gradx back: ', dxb)\n",
    "    nprint('gradx forward: ', dxf)\n",
    "test_gradx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradx(M,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarly, graident in y\n",
    "Be careful because numpy array's row indexing order is the opposite of Cartesian y-axis's direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backwardy_kernel = np.atleast_2d([1,-1]).T\n",
    "forwardy_kernel = np.atleast_2d([1,-1,0]).T\n",
    "grady_forward = correlate2d(test, forwardy_kernel, mode='same')\n",
    "grady_backward = correlate2d(test, backwardy_kernel, mode='same')\n",
    "nprint('original: ', test)\n",
    "nprint('forward y', grady_forward)\n",
    "nprint('backward y', grady_backward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sunnary: \n",
    "Kernels for spatial gradients of $\\phi$\n",
    "- mode: forward, backward\n",
    "- directions: x and y \n",
    "- Dxp (forward gradx),Dxm (backward gradx), Dyp, Dym "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSKernel():\n",
    "    forward_x = np.atleast_2d([-1,1]) # same as np.atleast_2d([0,-1,1]) #forward difference kernel for x-direction\n",
    "    backward_x = np.atleast_2d([-1,1,0])\n",
    "    \n",
    "    forwardy_kernel = np.atleast_2d([1,-1,0]).T\n",
    "    backwardy_kernel = np.atleast_2d([1,-1]).T\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSKernel.forward_x\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Time Comparison \n",
    "Element-by-element finite difference vs. correlation operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_naive(M):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    a tuple of backward and forward difference np.ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "    Dxf = np.empty_like(M)\n",
    "    Dxb = np.empty_like(M)\n",
    "\n",
    "    h,w = M.shape\n",
    "    for j in range(h):\n",
    "        for i in range(1, w-1):\n",
    "            Dxf[j,i] = M[j,i+1] - M[j,i]\n",
    "            Dxb[j,i] = M[j,i] - M[j,i-1]\n",
    "        # First column doesn't have valid values take the backward difference with\n",
    "        # Instead, take forward difference\n",
    "        Dxf[j,0] = M[j,1] - M[j,0]\n",
    "        Dxb[j,0] = M[j,1] - M[j,0]\n",
    "\n",
    "        # Last column doesn't have valid values take the forward difference with\n",
    "        # Instead, take backward difference\n",
    "        Dxf[j, w-1]= M[j,w-1] - M[j,w-2]\n",
    "        Dxb[j, w-1]= M[j,w-1] - M[j,w-2]\n",
    "\n",
    "    return Dxb, Dxf\n",
    "def test_diff_naive():\n",
    "    M = test\n",
    "    dxb, dxf = diff_naive(M)\n",
    "    nprint(dxb, dxf)\n",
    "test_diff_naive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# LevelSet Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient2d(M, axis, method):\n",
    "    \"\"\"Assumes Cartesian Coordinate System's axis direction,\n",
    "    that is: \n",
    "    - xaxis increases as we move to the right\n",
    "    - yaxis increasea as we move up \n",
    "    Note the yaxis's direction is the oppostie of numpy's row indexing order\n",
    "    In other words, the forward difference in y direction (ie. axis=0) would \n",
    "    be implemented with numpy arrays as:\n",
    "    \n",
    "    grady[j][i] = M[j-1][i] - M[j][i]\n",
    "                  ---------\n",
    "            this is \"ahead\" in cartisian coordinate system, although the indexing in \n",
    "            numpy array goes the other way around\n",
    "                \n",
    "    \n",
    "    Args:\n",
    "    - M (np.array like)\n",
    "    - axis (int): axis along which to perform the correlation filtering\n",
    "    - method (str): difference computation method \n",
    "        - must be one of 'forward', 'backward', 'central'\n",
    "    \n",
    "    Returns\n",
    "    - Same shape np.ndarray as M \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def const_F(ls):\n",
    "    \"\"\"\n",
    "    Customize the speed function for your problem.\n",
    "    For example:\n",
    "    [todo]\n",
    "    F = -ls.curvature\n",
    "    F = -1 \n",
    "    ---\n",
    "    ls (LevelSet): can compute gradient, curvature, or return its current phi values (in a grid)\n",
    "    \n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "class LevelSet():\n",
    "\n",
    "    @staticmethod\n",
    "    def gradient(grid):\n",
    "        \"\"\"\n",
    "        Compute Dxp, Dxm, Dyp, Dym\n",
    "        \"\"\"\n",
    "        Dxp = correlate2d(grid,  LSKernel.forward_x, mode='same')\n",
    "        Dxm = correlate2d(grid,  LSKernel.backward_x, mode='same')\n",
    "        Dyp = correlate2d(grid,  LSKernel.forward_y, mode='same')\n",
    "        Dym = correlate2d(grid,  LSKernel.backward_y, mode='same')\n",
    "        return (Dxp, Dxm, Dyp, Dym)\n",
    "    \n",
    "    @staticmethod\n",
    "    def curvature(grid):\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    \"\"\"LevelSet Evolution according to an initial-valued problem given by a PDE\n",
    "    Args:\n",
    "    - F (callable): takes a LevelSet object and time index and returns a np array \n",
    "    with the same shape as the levelset's grid\n",
    "    \"\"\"\n",
    "    def __init__(self, w, h, step=1., t=0):\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "        self.grid = self.init_grid()#np.empty((h,w))\n",
    "        \n",
    "        self.step = step # grid step size\n",
    "        self.t = t# current time        \n",
    "            \n",
    "    def init_grid(self):\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def gradient(self):\n",
    "        \"\"\"\n",
    "        Compute Dxp, Dxm, Dyp, Dym\n",
    "        \"\"\"\n",
    "        Dxp = correlate2d(self.grid,  LSKernel.forward_x, mode='same')\n",
    "        Dxm = correlate2d(self.grid,  LSKernel.backward_x, mode='same')\n",
    "        Dyp = correlate2d(self.grid,  LSKernel.forward_y, mode='same')\n",
    "        Dym = correlate2d(self.grid,  LSKernel.backward_y, mode='same')\n",
    "        return (Dxp, Dxm, Dyp, Dym)\n",
    "    \n",
    "    def curvature(self):\n",
    "        \"\"\"\n",
    "        Compute curvature at each (x,y) point\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def propagate(self, F, dt):\n",
    "        \"\"\"\n",
    "        Equation 4.8 and 4.20\n",
    "        For stability in computing the spatial gradients, use Eqn. 4.33\n",
    "        \"\"\"\n",
    "        Dxp, Dxm, Dyp, Dym = self.gradient()\n",
    "        S = np.sign(F)\n",
    "        \n",
    "        Dx = np.maximum(S*Dxm, -S*Dxp)\n",
    "        Dy = np.maximum(S*Dym, -S*Dyp)\n",
    "        \n",
    "        Dmag = np.sqrt(Dx**2 + Dy**2)\n",
    "        \n",
    "        # update phi\n",
    "        self.grid -= dt* Dmag * F\n",
    "        \n",
    "        # update time\n",
    "        self.t += dt\n",
    "    def advect(self, V, dt):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - V (ndarray of shape (w,h,2)): containing x and y component of the vector field\n",
    "        - dt (float): time step size\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def reinit(self, method='sweep'):\n",
    "        \"\"\"\n",
    "        Reset current grid (phi function) to satisfy Eikonal equality\n",
    "        in Eqn. 4.12\n",
    "        \n",
    "        - method \n",
    "            - 'pde': solve eqn. 4.37 with current grid, until steady state\n",
    "            - 'fmm': fast marching method\n",
    "            - 'sweep' (default): paper [88]\n",
    "            - 'exact': paper [64]\n",
    "            \n",
    "            Default is 'sweep'\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "        \n",
    "        \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import correlate2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.diag([1,2,3]);A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.c_[ [1,1,0], [90,-10,0], [1,-1,9]];B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A*B #elementwise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.maximum(np.ones((2,2)), np.zeros((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Modified: Jul 22, 2019\n",
    "## todo: open a git issue on holoviews\n",
    "\n",
    "### For git issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.NdOverlay(contours).options({'Contours': {'color': 'Element'}})\n",
    "# hv.NdOverlay(contours).opts(hv.opts('Contours', color='Element'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.NdOverlay(contours).opts(hv.opts('Contours', color='Element'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmaps = list(hv.Palette.colormaps.keys())[1:]\n",
    "cmaps_filtered = [cmap for i,cmap in enumerate(cmaps) if i%3]\n",
    "\n",
    "print(cmaps_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other useful commands\n",
    "- resource: https://is.gd/1WFERD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmaps = list(hv.Palette.colormaps.keys())[1:]\n",
    "# cmaps_filtered = [cmap for i,cmap in enumerate(cmaps) if i%3]\n",
    "# from holoviews.plotting import list_cmaps\n",
    "# cmaps_filtered = list_cmaps(category='Mono Sequential', reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nd_contours.opts(opts.Contours(color=hv.Cycle(['red','green','blue'])))\n",
    "nd_contours.options({'Contours': dict(cmap=hv.Cycle(cmaps_filtered))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmaps_filtered is a list of cmaps I chose manually\n",
    "for step_idx in range(10):\n",
    "    img = hv.Image( (xs, ys, zz), group=f'{step_idx}' )\n",
    "    contour = hv.operation.contours(zz_img, levels=0).relabel(group=f'{step_idx}') \\\n",
    "                .opts(xlim=xrange, ylim=yrange, cmap=cmaps_filtered[step_idx%len(cmaps_filtered)])\n",
    "\n",
    "    contours[step_idx] = contour\n",
    "nd_contours = hv.NdOverlay(contours, group='Contours', kdims='step')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours_cmapped = {}\n",
    "for cmap in cmaps:\n",
    "    try: \n",
    "        contours_cmapped[cmap]=hv.operation.contours(hv_img).opts(cmap=cmap)\n",
    "    except:\n",
    "        print('**failed: ', cmap)\n",
    "cmap_filtered = [cmap for i,cmap in enumerate(cmaps) if i%3]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.NdLayout({k:v for i,(k,v) in enumerate(contours_cmapped.items()) if i%3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Snippets \n",
    "- for gradient computation and visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compute gradients\n",
    "gradx = correlate2d(zz, kernel, mode='same')\n",
    "grady = correlate2d(zz, kernel.T, mode='same')\n",
    "\n",
    "ang, mag = u.UV2angMag(gradx, grady)\n",
    "\n",
    "gradfield = hv.VectorField((xs, ys, ang, mag)).opts(vfield_opts)\n",
    "gradmag_img = hv.Image( (xs,ys,np.abs(mag)), group='grad', label='t0' ).opts(img_opts).opts(xlim=xrange, ylim=yrange)\n",
    "\n",
    "overlay = datashade(zz0_img, cmap=GnBu9) * zz0_contour * gradfield + gradmag_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio as iio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = iio.imread('../data/test/gradient.jpg')\n",
    "bounds\n",
    "print(test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = np.meshgrid(range(test_img.shape[1]), range(test_img.shape[0]))\n",
    "test_x.shape, test_y.shape\n",
    "# hv.RGB(test_img. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,g,b = np.dsplit(test_img, test_img.shape[-1])\n",
    "bounds = (0, 0, test_x.shape[1], test_x.shape[0])\n",
    "(\n",
    "    hv.Image( r.squeeze(), bounds=bounds)\n",
    "    +  hv.Image( g.squeeze(), bounds=bounds)\n",
    "    +  hv.Image( b.squeeze(), bounds=bounds)\n",
    ").cols(1).opts(\n",
    "    opts.Image(height=test_x.shape[0], width=test_x.shape[1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vec2 as vec2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurveSimulator(param.Parameterized):\n",
    "\n",
    "    n_steps = param.Integer(label='Number of simulation steps', default=100)\n",
    "    p = param.ObjectSelector(label='p', default=0., objects=np.linspace(0,1,num=n_steps.default))\n",
    "    reset = param.Action(lambda x: x.reset_handler(), doc=\"Click to clear the buffer and reset p\")\n",
    "    t_interval = param.Number(label='t_interval', doc='Time interval between plotting two points',\n",
    "                              softbounds=(0., 5.),\n",
    "                              default=0.)\n",
    "\n",
    "    \n",
    "    ################################################################################\n",
    "    # Constant class properties\n",
    "    ################################################################################\n",
    "    H,W = 500,500\n",
    "    curve_opts = opts.Points(size=5,width=W, height=H, \n",
    "                             xlim=(-1,1), ylim=(-1,1),\n",
    "                             color=dim('p')*256-50,\n",
    "                             tools=['hover']\n",
    "                            )\n",
    "    xopts = opts.Points('XCoord', width=W, height=H, size=5, xlim=(0,1), \n",
    "                        padding=0.1, invert_axes=True, invert_yaxis=True)\n",
    "    yopts = opts.Points('YCoord', width=W, height=H, size=5, xlim=(0,1), padding=0.1, invert_xaxis=True)\n",
    "    \n",
    "    \n",
    "    ################################################################################\n",
    "    # Parameter Dependencies\n",
    "    ################################################################################    \n",
    "    @param.depends('n_steps', watch=True)\n",
    "    def _update_p(self):\n",
    "        self.count['p'] += 1\n",
    "        self.param['p'].objects = np.linspace(0,1,num=self.n_steps)\n",
    "        print('updated p with new number of simulation steps: ', self.n_steps)\n",
    "    \n",
    "    @param.depends('p', watch=True)\n",
    "    def send_point(self):\n",
    "        point = pd.DataFrame([(self.p, *self.cfunc(self.p))], columns=['p','x','y'])\n",
    "        self.data_src.emit(point)\n",
    "        time.sleep(self.t_interval)\n",
    "        \n",
    "    def reset_handler(self):\n",
    "        self.set_param(p=0.0)\n",
    "        self.dfstream.clear()\n",
    "\n",
    "        \n",
    "    ################################################################################\n",
    "    # Initialization\n",
    "    ################################################################################\n",
    "    def __init__(self, cfunc, n_steps=100, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - cfunc (function): given an input of a float p in [0,1], returns (x,y), a \n",
    "        tuple of x and y coords\n",
    "        \n",
    "        - n_steps (int): number of simulation steps along the range of [0,1] for \n",
    "        the parameter, p\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs) # this is super important\n",
    "        self.cfunc = cfunc \n",
    "        self.n_steps = n_steps\n",
    "        \n",
    "        self.example = pd.DataFrame({'p': [], 'x':[], 'y':[]})\n",
    "        self.data_src = streamz.dataframe.DataFrame(example=self.example)\n",
    "        self.dfstream = Buffer(self.data_src, length=min(self.n_steps, 100), index=False)\n",
    "        self.set_dmap_curve()\n",
    "        self.set_dmap_x()\n",
    "        self.set_dmap_y()\n",
    "        self.overlay = (self.dmap_curve + self.dmap_y + self.dmap_x).cols(2)\n",
    "    \n",
    "\n",
    "    def set_dmap_curve(self):\n",
    "        dmap_curve = hv.DynamicMap(\n",
    "            lambda data: hv.Points(data, kdims=['x','y'], group='Curve'),\n",
    "            streams=[self.dfstream])#.opts(color='p')\n",
    "        self.dmap_curve = dmap_curve.opts(self.curve_opts)\n",
    "        \n",
    "    def set_dmap_x(self):\n",
    "        dmap_x = hv.DynamicMap(\n",
    "            lambda data: hv.Points( data, kdims=['p','x'], group='XCoord'),\n",
    "            streams=[self.dfstream]).opts(color='p')\n",
    "        self.dmap_x = dmap_x.opts(self.xopts)\n",
    "        \n",
    "    def set_dmap_y(self):\n",
    "        dmap_y = hv.DynamicMap(\n",
    "            lambda data: hv.Points( data, kdims=['p','y'], group='YCoord'),\n",
    "            streams=[self.dfstream]).opts(color='p')\n",
    "        self.dmap_y = dmap_y.opts(self.yopts)\n",
    "    \n",
    "    \n",
    "    ################################################################################\n",
    "    # Display DynammicMaps\n",
    "    ################################################################################ \n",
    "    def viewable(self):\n",
    "        return self.overlay\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define curve function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfunc = lambda p: np.sin(2*np.pi*p)\n",
    "yfunc = lambda p: np.cos(2*np.pi*p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different functions\n",
    "xfunc = lambda p: np.sin(2*np.pi*p)**2\n",
    "yfunc = lambda p: np.cos(2*np.pi*p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfunc = lambda p: np.sin(2*np.pi*p)**10\n",
    "yfunc = lambda p: np.cos(2*np.pi*p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternating along a straight line \n",
    "xfunc = lambda p: np.sin(2*np.pi*p)**2\n",
    "yfunc = lambda p: np.cos(2*np.pi*p)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't have to choose a periodic function\n",
    "xfunc = lambda p: np.log(p)\n",
    "yfunc = lambda p: p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something happens at p=0.5\n",
    "xfunc = lambda p: np.sin(2*np.pi*p**2)*p**3\n",
    "yfunc = lambda p: np.sin(np.pi*p**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the simulator for the curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfunc = lambda p: (xfunc(p), yfunc(p))\n",
    "c = CurveSimulator(cfunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Row(\n",
    "    pn.Param(c.param, width=500, widgets={\n",
    "        'p': pn.widgets.DiscretePlayer,\n",
    "        'reset': pn.widgets.Button(name=c.param['reset'].label),\n",
    "        't_interval': pn.widgets.FloatSlider\n",
    "    }),\n",
    "    pn.panel(c.viewable())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.dfstream.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:earthml_v2]",
   "language": "python",
   "name": "conda-env-earthml_v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
