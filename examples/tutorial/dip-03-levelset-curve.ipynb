{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified: Jul 17, 2019\n",
    "# Curve Representation using Levelset function\n",
    "- Signed Distance Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, time\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.signal import correlate2d\n",
    "import pandas as pd\n",
    "    \n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "p = print\n",
    "\n",
    "from functools import lru_cache\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "import pdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "# Don't generate bytecode\n",
    "sys.dont_write_bytecode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import xarray as xr\n",
    "\n",
    "from holoviews import opts, dim\n",
    "from holoviews.operation.datashader import datashade, shade, dynspread, rasterize\n",
    "from holoviews.streams import Stream, param\n",
    "from holoviews import streams\n",
    "\n",
    "\n",
    "import panel as pn\n",
    "from bokeh.palettes import GnBu9\n",
    "\n",
    "\n",
    "hv.notebook_extension('bokeh')\n",
    "hv.Dimension.type_formatters[np.datetime64] = '%Y-%m-%d'\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the utils directory to the search path\n",
    "UTILS_DIR = Path('../utils').absolute()\n",
    "assert UTILS_DIR.exists()\n",
    "if str(UTILS_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(UTILS_DIR))\n",
    "    print(f\"Added {str(UTILS_DIR)} to sys.path\")\n",
    "\n",
    "# pp(sys.path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_mro as mro, nprint, timeit\n",
    "import utils as u\n",
    "\n",
    "import sdfs \n",
    "from vector import Vector as vec\n",
    "from samples import LSTestSample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set visualization options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = 500,500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.defaults(\n",
    "    opts.Image(colorbar=True, active_tools=['wheel_zoom'], tools=['hover']),\n",
    "    opts.Curve(tools=['hover'], active_tools=['wheel_zoom']),\n",
    "    opts.RGB(active_tools=['wheel_zoom'], tools=['hover'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_opts = opts.Image(height=H, width=W)\n",
    "vfield_opts = opts.VectorField(width=W, height=H, color='Magnitude',\n",
    "#                                magnitude=dim('Magnitude').norm()*0.2,\n",
    "                               pivot='tip',\n",
    "                               rescale_lengths=True)\n",
    "curve_opts = opts.Points(size=5,width=W, height=H, padding=0.1, \n",
    "                         legend_position='bottom',\n",
    "#                             xlim=(-10,10), ylim=(-10,10),\n",
    "#                         color=dim('p')*256-50\n",
    "                        )\n",
    "contour_opts = opts.Contours(width=W, height=H, \n",
    "                             colorbar=False,\n",
    "                             legend_position='bottom',\n",
    "                             tools=['hover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab registered bokeh renderer\n",
    "print(\"Currently available renderers: \", *hv.Store.renderers.keys())\n",
    "renderer = hv.renderer('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamz\n",
    "import streamz.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deinf a curve on a plane (ie. planary curve) we need\n",
    "- parameter, eg. p $\\in [0,1]$\n",
    "- two functions $x(p)$ and $y(p)$, which define the coordinate of the point $C(p)$ in x and y axis, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signed Distance Function \n",
    "### For a circle\n",
    "\n",
    "- $\\phi(x,y)$ is the distance between point $p = (x,y)$ and the curve. Here the curve we want to represent is a unit circle\n",
    "- $\\phi(x,y)$ is Dist(origin, $p$) - Dist(origin, a point on the unit circle touched by a stright ray passing through the origin and $p$). The second term is always 1 for a unit circle. So we get the $\\phi$ as following:\n",
    "\n",
    "$ \\phi(x,y) = \\sqrt{(x^2+y^2)} - 1 $\n",
    "\n",
    "Now let's visualize it using holoviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(x,y):\n",
    "    \"\"\"Signed Distance function for a unit circle\"\"\"\n",
    "    return np.sqrt(x**2 + y**2) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "xs = np.linspace(-1.5,1.5,num=n)\n",
    "ys = np.linspace(-1.5,1.5,num=n)[::-1] #flipped because I'm interested in the cartesian coordinate system's view\n",
    "# nprint(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = np.meshgrid(xs,ys)\n",
    "Z = phi(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See hv.Image?\n",
    "cmap = ['twilight', 'RdBu','Spectral']\n",
    "img = hv.Image((xs,ys,Z)).opts(img_opts).opts(cmap=cmap[1])\n",
    "contour = hv.operation.contours(img, levels=1).opts(contour_opts).opts(cmap='gray') #love this level=0:D\n",
    "img * contour\n",
    "#or, equivalently hv.Image(Z, bounds=(xs.min(), ys.min(), xs.max(), ys.max())).opts(img_opts)#.opts(cmap='twilight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[-0.5,0,0.5]])\n",
    "corr_opts = dict(mode='same')\n",
    "Zx = correlate2d(Z,kernel, **corr_opts)\n",
    "Zy= correlate2d(Z, kernel.T, **corr_opts)\n",
    "\n",
    "(\n",
    "    hv.Image((xs,ys,Zx)) + hv.Image((xs,ys,Zy))\n",
    ").opts(img_opts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_contour(xs, ys, Z, cmap=None, show_contour=True, levels=1):\n",
    "    if cmap is None:\n",
    "        cmap=dict(img_cmap='RdBu', contour_cmap='gray')\n",
    "    img = hv.Image((xs,ys,Z)).opts(img_opts).opts(cmap=cmap['img_cmap'])\n",
    "    contour = hv.operation.contours(img, levels=levels).opts(contour_opts).opts(cmap=cmap['contour_cmap']) #love this level=0:D\n",
    "    if show_contour:\n",
    "        return img*contour\n",
    "    return img\n",
    "\n",
    "def UV2angMag(U,V):\n",
    "    \"\"\"\n",
    "    U,V (MxN np.ndarray): encodes X,Y coordinate grids respectively\n",
    "    Returns:\n",
    "    - angle, mag: tuple of MxN np.ndarray that encode ang (or mag) for the grid space\n",
    "    That means, angle[j][i] at (X[j][i],Y[j][i]) location\n",
    "    \"\"\"\n",
    "    mag = np.sqrt(U**2 + V**2)\n",
    "    angle = (np.pi/2.) - np.arctan2(U/mag, V/mag)\n",
    "#     angle =  np.arctan2(V,U)\n",
    "\n",
    "\n",
    "    return (angle, mag)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_contour(xs,ys,Zx)+ img_contour(xs,ys,Zy)#,show_contour=False, levels=5)\n",
    "grad_angle, grad_mag = UV2angMag(Zx,Zy)\n",
    "gradfield = hv.VectorField( (X,Y,grad_angle, grad_mag) ).opts(vfield_opts)#.opts(height=1000, width=1000)\n",
    "\n",
    "# img.opts(height=1000,width=1000) * contour * gradfield\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Modified: Jul 21, 2019\n",
    "\n",
    "## Curve Evolution \n",
    "- [ ] Finite Difference method on parametric equations\n",
    "- [ ] Levelset functions\n",
    "    - 2D signed distance functions: [src](https://is.gd/t7p5mk)\n",
    "- [ ] Active contour on satellite images\n",
    "- [ ] Agent-based modelling with specified rules\n",
    "    - satellite image segmentation (~ clustering based on local features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sdf(xs, ys, sdFunc):\n",
    "    zz = np.empty( (len(ys), len(xs)) )\n",
    "    \n",
    "    for j in range(len(ys)):\n",
    "        for i in range(len(xs)):\n",
    "            q = vec(xs[i],ys[j])\n",
    "            zz[j,i] = sdFunc(q)\n",
    "    return zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE = {}\n",
    "HITS = defaultdict(int)\n",
    "\n",
    "t = 0\n",
    "xrange = (-1,1)\n",
    "yrange=(-1,1)\n",
    "n_points = 100\n",
    "xs = np.linspace(*xrange,num=n_points)\n",
    "ys = np.linspace(*yrange,num=n_points)\n",
    "\n",
    "sdf = sdfs.sdUnitCircle\n",
    "key = str((xrange, yrange, n_points, sdf))\n",
    "\n",
    "try:\n",
    "    zz = CACHE[key]\n",
    "    HITS[key] += 1\n",
    "\n",
    "except KeyError:\n",
    "    zz = eval_sdf(xs, ys, sdf)\n",
    "    CACHE[key] = zz\n",
    "\n",
    "zz0_img = hv.Image( (xs, ys, zz), group='zz', label='t0' ).opts(img_opts)\\\n",
    "            .opts(xlim=xrange, ylim=yrange)\n",
    "zz0_contour = hv.operation.contours(zz_img, levels=0, group='contour').opts(contour_opts) \\\n",
    "            .opts(xlim=xrange, ylim=yrange, cmap='gray')\n",
    "\n",
    "# compute gradients\n",
    "gradx = correlate2d(zz, kernel, mode='same')\n",
    "grady = correlate2d(zz, kernel.T, mode='same')\n",
    "\n",
    "ang, mag = u.UV2angMag(gradx, grady)\n",
    "\n",
    "gradfield = hv.VectorField((xs, ys, ang, mag)).opts(vfield_opts)\n",
    "gradmag_img = hv.Image( (xs,ys,np.abs(mag)), group='grad', label='t0' ).opts(img_opts).opts(xlim=xrange, ylim=yrange)\n",
    "\n",
    "overlay = datashade(zz0_img, cmap=GnBu9) * zz0_contour * gradfield + gradmag_img\n",
    "\n",
    "# overlay\n",
    "img0 = zz0_img *zz0_contour \n",
    "grad0 = gradmag_img * zz0_contour\n",
    "img0+grad0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz1 = zz - np.abs(mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz1_img = hv.Image( (xs,ys,zz1), group='zz', label='t1' ).opts(img_opts).opts(xlim=xrange, ylim=yrange)\n",
    "zz1_contour = hv.operation.contours(zz1_img, levels=0, group='contour').opts(contour_opts) \\\n",
    "            .opts(xlim=xrange, ylim=yrange, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = zz1_img *zz1_contour\n",
    "(img0 + img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.NdOverlay({1:zz0_contour, 2:zz1_contour})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step function to evolve the levelset equation for curve \n",
    "General curve evolution can be simulated as time integration process of the solving the following `initial value problem` for a general PDE:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\phi}{\\partial t} = L(t, \\phi(t)), ~~~~ \\phi(t_0) = \\phi^{0}\n",
    "$$\n",
    "\n",
    "Note that we will use $\\frac{\\partial \\phi}{\\partial t}$ and $\\phi_t$ interchangably, to denote the time derivative of $\\phi$.\n",
    "\n",
    "\n",
    "The first-order Taylor expansion about $(t+\\Delta t)$ gives,\n",
    "\n",
    "$$\n",
    "\\phi( t+\\Delta t) \\approx \\phi(t) + \\Delta t \\phi_{t}(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the [CFL](#) condition, if $L$ depends on at most the first-order derivatives (eg. $\\nabla \\phi$, the spatial derivative of $\\phi$), then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's implement the curve evolution according to this PDE:\n",
    "\n",
    "$$\n",
    "\\phi_{t}(x,y,t) = \\lVert \\nabla \\phi(x,y,t) \\rVert\n",
    "$$\n",
    "\n",
    "1. Inputs\n",
    "    - phi (MxN) at current time\n",
    "2. Computation\n",
    "    - compute gradx, grady -> mag_grad\n",
    "    - next_phi = phi - abs(mag_grad)\n",
    "        - make hv.image of next_phi\n",
    "        - make hv.contour of next_phi\n",
    "        - save the contour into a list\n",
    "    - after all iterations, make ndOverlay from the list of contours -> thish will show the unit circle's evolution according to:\n",
    "\n",
    "$$\n",
    "\\phi_{t}(x,y,t) = \\left| \\nabla \\phi(x,y,t) \\right|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(xs, ys, zz, return_grad=True, **kwargs):\n",
    "    \"\"\"\n",
    "    One step of curve evolution of levelset function. \n",
    "    In other words, this function defins a discrete version of PDE for a curve evolution \n",
    "    Returns current zz's gradients and next zz\n",
    "    \n",
    "    Args:\n",
    "    - xs (1D array of length N): x-coordinates\n",
    "    - ys (1D array of length M): y-coordinates\n",
    "    - zz (MxN np.ndarray): values of the levelset function s.t.\n",
    "        zz[j][i] = phi(x=xs[i], y=ys[j])\n",
    "        \n",
    "    - kwargs (dict) may have the following (key, value) pairs:\n",
    "        - \"step_idx\" -> (int) : indicating the iteration index following the (discreate) curve evolution equation\n",
    "    \n",
    "    Returns:\n",
    "    - a tuple of MxN np.ndarray(s): \n",
    "        If return_grad is True, returns (grad_ang, grad_mag, next_zz), or (next_zz)\n",
    "        where next_zz encodes the levelset values after a single step of curve evolution\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute gradients\n",
    "    gradx = correlate2d(zz, kernel, mode='same')\n",
    "    grady = correlate2d(zz, kernel.T, mode='same')\n",
    "\n",
    "    grad_ang, grad_mag = u.UV2angMag(gradx, grady)\n",
    "    next_zz = zz - np.abs(grad_mag)\n",
    "    if return_grad:\n",
    "        return (grad_ang, grad_mag, next_zz)\n",
    "    else:\n",
    "        return (next_zz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize curve evolution\n",
    "## First, define xs, ys ,and initial zz\n",
    "CACHE = {}\n",
    "HITS = defaultdict(int)\n",
    "\n",
    "xrange = (-1,1)\n",
    "yrange=(-1,1)\n",
    "n_points = 100\n",
    "xs = np.linspace(*xrange,num=n_points)\n",
    "ys = np.linspace(*yrange,num=n_points)\n",
    "\n",
    "# sdf = sdfs.sdUnitCircle\n",
    "sdf = sdfs.sdUnitHline\n",
    "\n",
    "zz = eval_sdf(xs, ys, sdf)\n",
    "\n",
    "n_steps = 10\n",
    "step_idx = 0\n",
    "\n",
    "contours = {}\n",
    "\n",
    "cmaps_filtered = ['Reds','Oranges', 'YlOrRd', 'Greens', 'Blues', 'PuBuGn', 'PuRd', 'Purples', 'Greys']\n",
    "while step_idx < n_steps:\n",
    "    zz_img = hv.Image( (xs, ys, zz), group=f'{step_idx}' ).opts(img_opts) \\\n",
    "                .opts(xlim=xrange, ylim=yrange)\n",
    "    zz_contour = hv.operation.contours(zz_img, levels=0).relabel(group=f'{step_idx}').opts(contour_opts) \\\n",
    "                .opts(xlim=xrange, ylim=yrange, cmap=cmaps_filtered[step_idx%len(cmaps_filtered)])\n",
    "\n",
    "    contours[step_idx] = zz_contour\n",
    "\n",
    "    # get current gradients and update levelset to next step\n",
    "    grad_ang, grad_mag, next_zz = step(xs, ys, zz)\n",
    "    gradfield = hv.VectorField((xs, ys, grad_ang, grad_mag), group=f'{step_idx}').opts(vfield_opts)\n",
    "\n",
    "    zz = next_zz\n",
    "    step_idx += 1\n",
    "nd_contours = hv.NdOverlay(contours, group='Contours', kdims='step')#.opts(hv.opts('Contours', color='step'))\n",
    "nd_contours;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take 2: Better coloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize curve evolution\n",
    "## First, define xs, ys ,and initial zz\n",
    "CACHE = {}\n",
    "HITS = defaultdict(int)\n",
    "\n",
    "xrange = (-5,5)\n",
    "yrange=(-5,5)\n",
    "n_points = 100\n",
    "xs = np.linspace(*xrange,num=n_points)\n",
    "ys = np.linspace(*yrange,num=n_points)\n",
    "\n",
    "# sdf = sdfs.sdUnitCircle\n",
    "sdf = sdfs.sdUnitHline\n",
    "zz = eval_sdf(xs, ys, sdf)\n",
    "\n",
    "n_steps = 20\n",
    "step_idx = 0\n",
    "\n",
    "contours = {}\n",
    "while step_idx < n_steps:\n",
    "    zz_img = hv.Image( (xs, ys, zz), group=f'{step_idx}' ).opts(img_opts) \\\n",
    "                .opts(xlim=xrange, ylim=yrange)\n",
    "    zz_contour = hv.operation.contours(zz_img, levels=0).relabel(group=f'{step_idx}').opts(contour_opts) \\\n",
    "                .opts(xlim=xrange, ylim=yrange)\n",
    "\n",
    "    contours[step_idx] = zz_contour\n",
    "\n",
    "    # get current gradients and update levelset to next step\n",
    "    grad_ang, grad_mag, next_zz = step(xs, ys, zz)\n",
    "    gradfield = hv.VectorField((xs, ys, grad_ang, grad_mag), group=f'{step_idx}').opts(vfield_opts)\n",
    "\n",
    "    zz = next_zz\n",
    "    step_idx += 1\n",
    "\n",
    "\n",
    "# Put each (single-layer) contour line together into a single contours element\n",
    "all_contours = hv.Contours([contour.add_dimension('step', 1, i, vdim=True) \n",
    "                            for i, contour in contours.items()], vdims=['z', 'step']).opts(contour_opts) \n",
    "all_contours.opts(cmap='Greens_r',color='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Ramesh-X/ModelViewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Please refer to this [thesis](#) for more details\n",
    "\n",
    "## Fundamental level-set equations\n",
    " \n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\phi}{\\partial{t}} &= -\\nabla{\\phi} \\cdot \\vec{V}  \\label{eq:4.7}  \\tag{4.7} \\\\\n",
    "                                  &= \\lVert \\vec{\\nabla} \\phi \\rVert F(\\vec{x}, \\vec{n}, \\phi, ... )\n",
    "                                     \\label{eq:4.8}  \\tag{4.8} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Key:\n",
    "- $Eqn. \\ref{eq:4.7}$: describes the transportation of the interface (ie. curve) in an external vector field\n",
    "- $Eqn. \\ref{eq:4.8}$: describes the motion of the interface in its normal direction by a magnitude determined by the speed function, $F$\n",
    "    - $F = $ const \n",
    "    - $F = - \\alpha \\kappa$ for some $ \\alpha > 0$ \n",
    "\n",
    "\n",
    "## <mark> Stability of the solution </mark> [todo]\n",
    "### 1. Choice of discrete spatial derivative -- forward, backward, central\n",
    "\n",
    "- If the levelset equation depends on at most order 1 derivatives:\n",
    "\n",
    "    For example, \n",
    "    $$\n",
    "    \\begin{align}\n",
    "    F &= 1 \\\\\n",
    "    \\Rightarrow \\frac{\\partial \\phi}{\\partial{t}} &= \\lVert \\vec{\\nabla} \\phi \\rVert\n",
    "    \\end{align}\n",
    "    $$\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "- If the levelset equation depends on derivatives of order $\\geq 2$:\n",
    "\n",
    "    For example, \n",
    "    $$\n",
    "    \\begin{align}\n",
    "    F &= - \\frac{1}{\\lVert \\vec{\\nabla} \\phi \\rVert} \\kappa \\\\\n",
    "    \\Rightarrow \\frac{\\partial \\phi}{\\partial{t}} &=  \\kappa\n",
    "    \\end{align}\n",
    "    $$\n",
    "    Recall that the curvature $\\kappa$ involves second derivatives of $\\phi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective 1: solve \\ref{eq:4.7} as an advection problem\n",
    "- **Advection**: transportation of the interface in an external vector field\n",
    "\n",
    "One way to implement the dynamic curve evolution is to view the curve (or surface in 3D) as a floating object in some flow field $\\vec{V}$ and solve the time integration of an **initial-valued problem** of the following PDE.  In continuous time domain, this is expressed as:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\phi}{\\partial t} = - \\vec{\\nabla} \\phi \\cdot \\vec{V}  \n",
    "$$\n",
    "\n",
    "where the vector $\\vec{\\nabla} \\phi$ refers to the spatial gradient of $\\phi$. Note that a vector normal to any levelset satisfies:\n",
    "\n",
    "$$\\vec{n} = \\frac{\\vec{\\nabla} \\phi}{ \\lVert \\vec{\\nabla} \\phi \\rVert }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, $\\ref{eq:4.7}$ is projecting each flow vector at $(x,y)$ on the grid to $\\vec{n}(x,y)$, which it takes into account just the component of the flow in the direction of the normal. \n",
    "\n",
    "### Up-winding \n",
    "- as a way to choose the correct direction of spatial derivative \n",
    "\n",
    "Let's denote the spatial gradient of $\\phi$ as $\\phi_{\\vec{x}} = (\\phi_x, \\phi_y)$.\n",
    "- The information need to compute the accurate spatial derivatives, $\\phi_x, \\phi_y$, comes from the **reverse direction** of the vector field flow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement discrete gradients \n",
    "Assume the input array is in Cartesian coordinate (rather than image coordinate or numpy array indexing order)\n",
    "\n",
    "- mode: forward, backward, central\n",
    "- axis: 0 (y-axis), 1 (x-axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use scipy `correlated2d`\n",
    "\n",
    "### First, gradient in x direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backwardx_kernel = np.atleast_2d([-1,1,0] )\n",
    "forwardx_kernel = np.atleast_2d([0,-1,1] )\n",
    "# unnecessary operation will be incurred because of the last zero, \n",
    "#but this ensures the center of kernel is overlaid on the location of interest\n",
    "test = np.array( [[1,2,5,10,100], \n",
    "                  [0,-1,10,-3,9],\n",
    "                  [100,-20, 8, 10,-10]]\n",
    "               )\n",
    "gradx_backward = correlate2d(test, backwardx_kernel, mode='same')\n",
    "gradx_forward = correlate2d(test, forwardx_kernel, mode='same')\n",
    "\n",
    "nprint('original', test)\n",
    "nprint('gradx back: ', gradx_backward)\n",
    "nprint('gradx forward: ', gradx_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the top-left element in the backward gradient in x (`gradx back`). Since it corresponds to the location in xy-plane at x=0, there is no previous value to compute its backward difference from. We can handle this case in several different ways:\n",
    "\n",
    "- use the value as is: this is equialent to pad zero as the leftmost column. use boundary='fill' and fillvalue=0\n",
    "- use the forward difference: this is equivalent to use boundary='symm' \n",
    "\n",
    "The first method is what we tried above since it's the default setting of `correlate2d`. Let's check the second method now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradx_backward = correlate2d(test, backwardx_kernel, mode='same', boundary='symm')\n",
    "gradx_forward = correlate2d(test, forwardx_kernel, mode='same', boundary='symm')\n",
    "\n",
    "nprint('original', test)\n",
    "nprint('gradx back: ', gradx_backward)\n",
    "nprint('gradx forward: ', gradx_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, so it seems like 'symm' option actually copies starting as the edge column. This is not the forward difference. With our `backwardx_kernel`, this will always result zero column. So let's instead just replace the first column of the `gradx_backward` with the first column of the `gradx_forward`.  Similarly, we can handle the other edge case (ie. the last column of the output `gradx_forward` where the forward value to take the forward difference with do not exist, by placing it with the backward difference values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backwardx_kernel = np.atleast_2d([-1,1,0] )\n",
    "forwardx_kernel = np.atleast_2d([0,-1,1] )\n",
    "\n",
    "test = np.array( [[1,2,5,10,100], \n",
    "                  [0,-1,10,-3,9],\n",
    "                  [100,-20, 8, 10,-10]]\n",
    "               )\n",
    "dxb = correlate2d(test, backwardx_kernel, mode='same')\n",
    "dxf = correlate2d(test, forwardx_kernel, mode='same')\n",
    "\n",
    "nprint('original', test)\n",
    "nprint('gradx back: ', dxb)\n",
    "nprint('gradx forward: ', dxf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now replace the first column of backwardx with the first column of forwardx \n",
    "# And replace the last column of the forwardx with the last column of backwardx\n",
    "dxb[:,0] = dxf[:,0]\n",
    "dxf[:,-1] = dxb[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backwardx_kernel = np.atleast_2d([-1,1,0] )\n",
    "forwardx_kernel = np.atleast_2d([-1,1] )\n",
    "\n",
    "@timeit\n",
    "def gradx(M, switch):\n",
    "    dxb = correlate2d(M, backwardx_kernel, mode='same')\n",
    "    dxf = correlate2d(M, forwardx_kernel, mode='same')\n",
    "\n",
    "    if switch:\n",
    "        dxb[:,0] = dxf[:,0]\n",
    "        dxf[:,-1] = dxb[:,-1]\n",
    "\n",
    "    return dxb, dxf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gradx():\n",
    "    test = np.array( [[1,2,5,10,100], \n",
    "                  [0,-1,10,-3,9],\n",
    "                  [100,-20, 8, 10,-10]]\n",
    "                   )\n",
    "    switch = True\n",
    "    dxb, dxf = gradx(test, switch)\n",
    "    nprint('original', test)\n",
    "    nprint('gradx back: ', dxb)\n",
    "    nprint('gradx forward: ', dxf)\n",
    "test_gradx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarly, graident in y\n",
    "Be careful because numpy array's row indexing order is the opposite of Cartesian y-axis's direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backwardy_kernel = np.atleast_2d([1,-1]).T\n",
    "forwardy_kernel = np.atleast_2d([1,-1,0]).T\n",
    "grady_forward = correlate2d(test, forwardy_kernel, mode='same')\n",
    "grady_backward = correlate2d(test, backwardy_kernel, mode='same')\n",
    "nprint('original: ', test)\n",
    "nprint('forward y', grady_forward)\n",
    "nprint('backward y', grady_backward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Switching in y-direction\n",
    "\n",
    "When computing backward grady, elements in the last row does not have valid previous values to compute the backward difference. So we replace the last row of the `grady_backward` with the last row of the `grady_forward`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grady_backward[-1] = grady_forward[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the first row of the forward_y does not have valid next values to compute the forward difference with. So we replace the first row of the `grady_forward` with the first row of the `grady_backward`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grady_forward[0] = grady_backward[0]\n",
    "nprint('grady backward: ', grady_backward)\n",
    "nprint('grady forward: ', grady_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeit\n",
    "def grady(M, switch):\n",
    "    dyb = correlate2d(M, backwardy_kernel, mode='same')\n",
    "    dyf = correlate2d(M, forwardy_kernel, mode='same')\n",
    "\n",
    "    if switch:\n",
    "        dyb[-1] = dyf[-1]\n",
    "        dyf[0] = dyb[0]\n",
    "\n",
    "    return dyb, dyf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_grady():\n",
    "    M = test\n",
    "    dyb, dyf = grady(M,True)\n",
    "    nprint('original: ', M)\n",
    "    nprint('backword grady: ', dyb)\n",
    "    nprint('forward grady: ', dyf)\n",
    "test_grady()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Summary on how to compute spatial gradients\n",
    "Kernels for spatial gradients of $\\phi$\n",
    "- mode: forward, backward\n",
    "- directions: x and y \n",
    "- Dxp (forward gradx),Dxm (backward gradx), Dyp, Dym "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Modified: Jul 26, 2019\n",
    "### [SIDE] Computing Time Comparison \n",
    "Element-by-element finite difference vs. correlation operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeit\n",
    "def diff_naive(M):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    a tuple of backward and forward difference np.ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "    Dxf = np.empty_like(M)\n",
    "    Dxb = np.empty_like(M)\n",
    "\n",
    "    h,w = M.shape\n",
    "    for j in range(h):\n",
    "        for i in range(1, w-1):\n",
    "            Dxf[j,i] = M[j,i+1] - M[j,i]\n",
    "            Dxb[j,i] = M[j,i] - M[j,i-1]\n",
    "        # First column doesn't have valid values take the backward difference with\n",
    "        # Instead, take forward difference\n",
    "        Dxf[j,0] = M[j,1] - M[j,0]\n",
    "        Dxb[j,0] = M[j,1] - M[j,0]\n",
    "\n",
    "        # Last column doesn't have valid values take the forward difference with\n",
    "        # Instead, take backward difference\n",
    "        Dxf[j, w-1]= M[j,w-1] - M[j,w-2]\n",
    "        Dxb[j, w-1]= M[j,w-1] - M[j,w-2]\n",
    "\n",
    "    return Dxb, Dxf\n",
    "def test_diff_naive():\n",
    "    M = test\n",
    "    dxb, dxf = diff_naive(M)\n",
    "    nprint(dxb, dxf)\n",
    "test_diff_naive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.random.randn(1000,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = diff_naive(M);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = gradx(M,True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(out1, out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oh wow. These is a big speedup from vectorizing the computatation. Let's go with the correlated2d based function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# LevelSet Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calculus as calc\n",
    "from grid import CartesianGrid\n",
    "from samples import LSTestSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LevelSet():\n",
    "    \"\"\"LevelSet Evolution according to an initial-valued problem given by a PDE\n",
    "    Args:\n",
    "    - F (callable): takes a LevelSet object and time index and returns a np array \n",
    "    with the same shape as the levelset's grid\n",
    "    \"\"\"\n",
    "    def __init__(self, grid=None, grid_step=1., t=0):\n",
    "\n",
    "        if grid is None:\n",
    "            grid = self.get_test_grid()\n",
    "        self.grid = grid\n",
    "        self.h, self.w = grid.shape\n",
    "          \n",
    "        self.grid_step = grid_step # grid step size\n",
    "        self.delta = np.inf # average change in grid values\n",
    "        self.t = t# current time        \n",
    "            \n",
    "    def initialize_grid(self):\n",
    "        pass\n",
    "    \n",
    "    def run(self, F, dt, pde_class, threshold=1e-3, maxIter=1e4):\n",
    "        count = 0\n",
    "        deltas = []\n",
    "        grids = {}\n",
    "        while self.delta > threshold:\n",
    "            if count > maxIter: \n",
    "                print(\"MaxIter reached: \", count)\n",
    "                break\n",
    "            self.propagate(F,dt,pde_class)\n",
    "            deltas.append(self.delta)\n",
    "            count += 1\n",
    "            if count%1000:\n",
    "                grids[self.t] = self.grid\n",
    "        print(f\"Ran for {count} steps, for {self.t} periods\")\n",
    "        print(f\"\\taverage delta phi: {self.delta}\")\n",
    "        return deltas, grids\n",
    "\n",
    "    def propagate(self, F, dt, pde_class):\n",
    "        \"\"\"\n",
    "        Equation 4.8 and 4.20\n",
    "        For stability in computing the spatial gradients, use Eqn. 4.33\n",
    "        \n",
    "        pde_class (str): 'hyperbolic', 'parabolic'\n",
    "            - 1: if F depends on at most order 1 derivatives of the levelset function phi \n",
    "            wrt space and time, the information propagation has a certain direction \n",
    "            (ie. \"characteristics\"), and we need to be careful about which gradient to \n",
    "            take -- backward? forward?  In this case, the levelset equation is 'hyperbolic', \n",
    "            a subclass of Hamilton-Jacobian equation. \n",
    "            \n",
    "            - 2: if F depends on derivatives of order >= 2 (eg. F = alpha*curvature),\n",
    "            then the information propagates from all directions, and we can use the \n",
    "            central finite difference method to compute the spatial gradients.\n",
    "        \"\"\"\n",
    "        assert pde_class in ['hyperbolic','parabolic'], \\\n",
    "        f\"pde_class must be either 1 or 2: {pde_class}\"\n",
    "        \n",
    "        if pde_class == 'hyperbolic':\n",
    "            dxb, dxf, dyb, dyf = self.get_bf_gradients()\n",
    "            \n",
    "            S = np.sign(F)\n",
    "            dx = np.maximum(S*dxb, -S*dxf)\n",
    "            dy = np.maximum(S*dyb, -S*dyf)\n",
    "\n",
    "            dmag = np.sqrt(dx**2 + dy**2)\n",
    "            \n",
    "        else :#pde_class == 'parabolic':\n",
    "            dx,dy = self.get_central_gradients()\n",
    "            dmag = comput_mag(dx,dy)# todo\n",
    "        \n",
    "        \n",
    "        # update phi\n",
    "        dphi = dt* dmag * F\n",
    "        self.delta = dphi.sum() / dphi.size\n",
    "        self.grid -= dphi \n",
    "        \n",
    "        # update time\n",
    "        self.t += dt\n",
    "    def advect(self, V, dt):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - V (ndarray of shape (w,h,2)): containing x and y component of the vector field\n",
    "        - dt (float): time step size\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def reinit(self, method='sweep'):\n",
    "        \"\"\"\n",
    "        Reset current grid (phi function) to satisfy Eikonal equality\n",
    "        in Eqn. 4.12\n",
    "        \n",
    "        - method \n",
    "            - 'pde': solve eqn. 4.37 with current grid, until steady state\n",
    "            - 'fmm': fast marching method\n",
    "            - 'sweep' (default): paper [88]\n",
    "            - 'exact': paper [64]\n",
    "            \n",
    "            Default is 'sweep'\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def get_bf_gradients(self, switch=True):\n",
    "        return gradient(self.grid, switch)\n",
    "    \n",
    "    def get_curvature(self):\n",
    "        return curvature(self.grid)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_test_grid():\n",
    "        return np.array([[1, 2, 5, 10, 100],\n",
    "                         [0, -1, 10, -3, 9],\n",
    "                        [100, -20, 8, 10,-10]], dtype = np.float)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs,ys,zz = LSTestSample.linear_array()\n",
    "hv.Image((xs,ys,zz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSEvolver(CartesianGrid):\n",
    "    \"\"\"\n",
    "    EvolvingLS\n",
    "    A levelSet evolution according to an initial-valued problem given by a PDE\n",
    "    Args:\n",
    "    - F (callable): takes a LevelSet object and time index and returns a np array \n",
    "    with the same shape as the levelset's grid\n",
    "    \"\"\"\n",
    "    def __init__(self, xs, ys, data=None, t=0):\n",
    "        super().__init__(xs, ys, data)\n",
    "        \n",
    "        self.time = t #current time\n",
    "        self.delta = np.inf # average change of LS function values between consecutive time stamps\n",
    "            \n",
    "    def run(self, F, dt, pde_class, threshold=1e-3, maxIter=1e4):\n",
    "        count = 0\n",
    "        deltas = []\n",
    "        phis = {}\n",
    "        while self.delta > threshold:\n",
    "            if count > maxIter: \n",
    "                print(\"MaxIter reached: \", count)\n",
    "                break\n",
    "            self.propagate(F,dt,pde_class)\n",
    "            deltas.append(self.delta)\n",
    "            count += 1\n",
    "            if count%1000:\n",
    "                phis[self.time] = self.data\n",
    "        print(f\"Ran for {count} steps, for {self.time} periods\")\n",
    "        print(f\"\\taverage delta phi: {self.delta}\")\n",
    "        return deltas, phis\n",
    "\n",
    "    def propagate(self, F, dt, pde_class):\n",
    "        \"\"\"\n",
    "        Equation 4.8 and 4.20\n",
    "        For stability in computing the spatial gradients, use Eqn. 4.33\n",
    "        \n",
    "        pde_class (str): 'hyperbolic', 'parabolic'\n",
    "            - 1: if F depends on at most order 1 derivatives of the levelset function phi \n",
    "            wrt space and time, the information propagation has a specific direction \n",
    "            (ie. \"characteristics\"), and we need to be careful about which gradient to \n",
    "            take -- backward, forward.  In this case, the levelset equation is 'hyperbolic', \n",
    "            which is a subclass of Hamilton-Jacobian equation. \n",
    "            \n",
    "            - 2: if F depends on derivatives of order >= 2 (eg. F = alpha*curvature),\n",
    "            then the information propagates from all directions, and we can use the \n",
    "            central finite difference method to compute the spatial gradients.\n",
    "        \"\"\"\n",
    "        if dt > min(self.dx, self.dy):\n",
    "            #todo: print error but then make dt smaller smartly\n",
    "            raise ValueError('dt should be smaller than x and y sample resolutions: ', dt)\n",
    "                \n",
    "        assert pde_class in ['hyperbolic','parabolic'], \\\n",
    "        f\"pde_class must be either 1 or 2: {pde_class}\"\n",
    "        \n",
    "        if pde_class == 'hyperbolic':\n",
    "            dxb, dxf, dyb, dyf = self.get_diff1_bf()\n",
    "            debug = (\n",
    "                hv.Image(self.data, label='phi') + hv.Image([])\n",
    "                + hv.Image(dxb, label='dx back') + hv.Image(dxf, label='dx forward')\n",
    "                + hv.Image(dyb, label='dy back') + hv.Image(dyf, label='dy forward')\n",
    "            ).cols(2)\n",
    "            display(debug)\n",
    "\n",
    "            S = np.sign(F)\n",
    "            dx = np.maximum(S*dxb, -S*dxf)\n",
    "            dy = np.maximum(S*dyb, -S*dyf)\n",
    "\n",
    "            dmag = np.sqrt(dx**2 + dy**2)\n",
    "            \n",
    "        else :#pde_class == 'parabolic':\n",
    "            dx,dy = self.get_diff1_central()\n",
    "            dmag = comput_mag(dx,dy)# todo\n",
    "        \n",
    "        \n",
    "        # update phi\n",
    "        dphi = dt* dmag * F\n",
    "        self.delta = dphi.sum() / dphi.size\n",
    "        self.data -= dphi \n",
    "        \n",
    "        # update time\n",
    "        self.time += dt\n",
    "        \n",
    "    def advect(self, V, dt):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - V (ndarray of shape (w,h,2)): containing x and y component of the vector field\n",
    "        - dt (float): time step size\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def reinit(self, method='sweep'):\n",
    "        \"\"\"\n",
    "        Reset current phi values (in self.data) to satisfy Eikonal equality\n",
    "        in Eqn. 4.12\n",
    "        \n",
    "        - method \n",
    "            - 'pde': solve eqn. 4.37 with current phi data, until steady state\n",
    "            - 'fmm': fast marching method\n",
    "            - 'sweep' (default): paper [88]\n",
    "            - 'exact': paper [64]\n",
    "            \n",
    "            Default is 'sweep'\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def get_diff1_bf(self, switch=True):\n",
    "        dxb, dxf, dyb, dyf = calc.diff1_bf(self.data, switch)\n",
    "        return dxb/self.dx, dxf/self.dx, dyb/self.dy, dyf/self.dy\n",
    "    \n",
    "    def get_diff1_central(self):\n",
    "        dx, dy= calc.diff1_central(self.data)\n",
    "        return dx/self.dx, dy/self.dy\n",
    "    \n",
    "    def get_curvature(self):\n",
    "        return curvature(self.data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs,ys,zz = LSTestSample.linear_array()\n",
    "ls = LSEvolver(xs,ys,zz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx,dy = ls.get_diff1_central()\n",
    "dxb, dxf,dyb,dyf = ls.get_diff1_bf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    hv.Image(zz,label='initial ls') \n",
    " + hv.Image(dx, label='initial dx central') \n",
    " + hv.Image(dy, label='initial dy central')\n",
    ").cols(2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for debuging diff1_central's dy sign flip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    hv.Image(dxb,label='initial dx back') \n",
    "     + hv.Image(dxf, label='initial dx forward') \n",
    "     + hv.Image(dyb, label='initial dy back')\n",
    "     + hv.Image(dyf, label='initial dy forward')\n",
    "\n",
    ").cols(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempy, tempx = np.gradient(zz)\n",
    "(\n",
    "    hv.Image(zz) \n",
    "    + hv.Image(tempx/ls.dx, label='dx') \n",
    "    + hv.Image(-tempy/ls.dy, label='dy')\n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! Fixed the sign bug. The problem was the np.gradient's positive yaxis is the opposite of Cartesian coordinate's positive yaxis. The later is the direction our underlying dataset (`ls.data`) is referenced to.\n",
    "\n",
    "Moving on the to the next step.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check propagate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 1\n",
    "dt = 1e-4\n",
    "ls.propagate(F, dt, 'hyperbolic')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo:\n",
    "- do this in arya\n",
    "- time profiling, why does it take so long?\n",
    "     - try with smaller maxiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_levelset():\n",
    "    xs,ys,zz = LSTestSample.unit_star1()\n",
    "    ls = LSEvolver(xs,ys,zz)\n",
    "    F = 1\n",
    "    dt = 1e-4\n",
    "    print(\"Initial t,delta: \", np.around(ls.time,1), np.around(ls.delta,3))\n",
    "    \n",
    "    deltas, phis = ls.run(F, dt, pde_class='hyperbolic', threshold=1e-9)\n",
    "    print(\"Final t,delta: \", np.around(ls.time,1), np.around(ls.delta,3))\n",
    "    plt.plot(deltas)\n",
    "test_levelset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the importance of `dt` in the delta graph. Try it with different values of dt, eg: `dt = =1, 0.5, 0.01, 0.001, 1e-4`.\n",
    "\n",
    "Now, let's try it on some signed distance functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_levelset_unit_circle():\n",
    "    n_points = 100\n",
    "    xlim = (-2,2)\n",
    "    ylim = (-2,2)\n",
    "    sdf = sdfs.sdUnitCircle\n",
    "    xs = np.linspace(*xlim,n_points)\n",
    "    ys = np.linspace(*ylim,n_points)[::-1]\n",
    "    zz = sdfs.eval_sdf(xs,ys,sdf)\n",
    "    base = hv.Image((xs,ys,zz))\n",
    "\n",
    "    \n",
    "    ls = LSEvolver(xs,ys,zz)\n",
    "    F = 1\n",
    "    dt = 1e-3\n",
    "\n",
    "    times = [ls.time]\n",
    "    deltas = [ls.delta]\n",
    "    phis = {ls.time : ls.data}\n",
    "    for i in range(100):\n",
    "        ls.propagate(F, dt=0.3, pde_class='hyperbolic')\n",
    "        times.append(ls.time)\n",
    "        deltas.append(ls.delta)\n",
    "        phis[ls.time] = ls.data.copy()\n",
    "#     plt.plot(deltas)\n",
    "    \n",
    "    dmap = hv.DynamicMap(\n",
    "    lambda t: hv.operation.contours(hv.Image((xs,ys,phis[t])),levels=10),\n",
    "    kdims='t')\n",
    "    dmap = dmap.redim.values(t=list(phis.keys())).opts(\n",
    "    opts.Contours(contour_opts), \n",
    "    opts.Image(img_opts))\n",
    "    \n",
    "    \n",
    "    # show results\n",
    "    plt.plot(deltas)\n",
    "    display (\n",
    "    base.opts(img_opts) \n",
    "    * dmap.opts(contour_opts)\n",
    "    )\n",
    "    return deltas, base, dmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWESOME!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas, base, dmap = test_levelset_unit_circle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    base.opts(img_opts) \n",
    "    * dmap.opts(contour_opts)\n",
    ")\n",
    "dmap#.opts(contour_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_levelset_unit_star1():\n",
    "#     xs, ys, zz = LSTestSample.unit_star1()\n",
    "#     xs, ys, zz = LSTestSample.unit_star2()\n",
    "    xs,ys,zz = LSTestSample.linear_array()\n",
    "\n",
    "\n",
    "    base = hv.Image((xs,ys,zz))\n",
    "\n",
    "\n",
    "    ls = LSEvolver(xs,ys,zz)\n",
    "    F = -1\n",
    "    dt = 0.3\n",
    "\n",
    "    times = [ls.time]\n",
    "    deltas = {ls.time: ls.delta}\n",
    "    phis = {ls.time : ls.data}\n",
    "    for i in range(100):\n",
    "        ls.propagate(F, dt=dt, pde_class='hyperbolic')\n",
    "        times.append(ls.time)\n",
    "        deltas[ls.time] = ls.delta\n",
    "        phis[ls.time] = ls.data.copy()\n",
    "\n",
    "    #holoviews elements\n",
    "    deltas.pop(0) # for yrange when visualized\n",
    "    curve_deltas = hv.Curve(deltas).opts(curve_opts)\n",
    "    dmap_contours = hv.DynamicMap(lambda t: hv.operation.contours(hv.Image((xs,ys,phis[t])),levels=0),\n",
    "                                  kdims='t')\n",
    "    dmap_contours = dmap_contours.redim.values(t=list(phis.keys())).opts(contour_opts,img_opts)\n",
    "    \n",
    "    dmap_tpoint= hv.DynamicMap(lambda t: hv.Points( [(t, deltas[t])]), kdims='t')\n",
    "    dmap_tpoint = dmap_tpoint.redim.values(t=list(deltas.keys())).opts(curve_opts)\n",
    "                      \n",
    "    # show results\n",
    "    overlay = (base*dmap_contours + curve_deltas * dmap_tpoint).opts(shared_axes=False)\n",
    "    display(overlay)\n",
    "    \n",
    "    return deltas, base, dmap_contours, curve_deltas, dmap_tpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas, base, dmap_contours, curve_deltas, dmap_tpoint= test_levelset_unit_star1();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmap_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(base*dmap_contours + curve_deltas * dmap_tpoint).opts(shared_axes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 100\n",
    "xlim = (-2,2)\n",
    "ylim = (-2,2)\n",
    "# sdf = sdfs.sdUnitCircle\n",
    "# sdf = sdfs.sdUnitHline\n",
    "sdf = sdfs.sdStar1\n",
    "# sdf = sdfs.sdStar2\n",
    "\n",
    "\n",
    "\n",
    "xs = np.linspace(*xlim,n_points)\n",
    "ys = np.linspace(*ylim,n_points)\n",
    "zz = sdfs.eval_sdf(xs,ys,sdf)\n",
    "\n",
    "# plt.imshow(zz.squeeze(), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = LevelSet(grid=zz)\n",
    "F = 1\n",
    "dt = 1\n",
    "base = hv.Image((xs,ys,ls.grid)).opts(img_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [ls.t]\n",
    "deltas = [ls.delta]\n",
    "grids = {ls.t: ls.grid}\n",
    "for i in range(100):\n",
    "    ls.propagate(F,dt=0.3, pde_class='hyperbolic')\n",
    "    times.append(ls.t)\n",
    "    deltas.append(ls.delta)\n",
    "    grids[ls.t]=ls.grid.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmap = hv.DynamicMap(\n",
    "    lambda t: hv.operation.contours(hv.Image((xs,ys,grids[t])),levels=10),\n",
    "    kdims='t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base * dmap.redim.values(t=list(grids.keys())).opts(\n",
    "    opts.Contours(contour_opts),\n",
    "    opts.Image(img_opts)\n",
    ").opts(legend_position='bottom')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmap.redim.range(t=(0.001).opts(contour_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmap = hv.DynamicMap(\n",
    "    lambda tidx: hv.operation.contours(hv.Image((xs,ys,temp[tidx])),levels=0),\n",
    "    kdims='tidx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Modified: Jul 22, 2019\n",
    "## todo: open a git issue on holoviews\n",
    "\n",
    "### For git issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.NdOverlay(contours).options({'Contours': {'color': 'Element'}})\n",
    "# hv.NdOverlay(contours).opts(hv.opts('Contours', color='Element'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.NdOverlay(contours).opts(hv.opts('Contours', color='Element'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmaps = list(hv.Palette.colormaps.keys())[1:]\n",
    "cmaps_filtered = [cmap for i,cmap in enumerate(cmaps) if i%3]\n",
    "\n",
    "print(cmaps_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other useful commands\n",
    "- resource: https://is.gd/1WFERD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmaps = list(hv.Palette.colormaps.keys())[1:]\n",
    "# cmaps_filtered = [cmap for i,cmap in enumerate(cmaps) if i%3]\n",
    "# from holoviews.plotting import list_cmaps\n",
    "# cmaps_filtered = list_cmaps(category='Mono Sequential', reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nd_contours.opts(opts.Contours(color=hv.Cycle(['red','green','blue'])))\n",
    "nd_contours.options({'Contours': dict(cmap=hv.Cycle(cmaps_filtered))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmaps_filtered is a list of cmaps I chose manually\n",
    "for step_idx in range(10):\n",
    "    img = hv.Image( (xs, ys, zz), group=f'{step_idx}' )\n",
    "    contour = hv.operation.contours(zz_img, levels=0).relabel(group=f'{step_idx}') \\\n",
    "                .opts(xlim=xrange, ylim=yrange, cmap=cmaps_filtered[step_idx%len(cmaps_filtered)])\n",
    "\n",
    "    contours[step_idx] = contour\n",
    "nd_contours = hv.NdOverlay(contours, group='Contours', kdims='step')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours_cmapped = {}\n",
    "for cmap in cmaps:\n",
    "    try: \n",
    "        contours_cmapped[cmap]=hv.operation.contours(hv_img).opts(cmap=cmap)\n",
    "    except:\n",
    "        print('**failed: ', cmap)\n",
    "cmap_filtered = [cmap for i,cmap in enumerate(cmaps) if i%3]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.NdLayout({k:v for i,(k,v) in enumerate(contours_cmapped.items()) if i%3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Snippets \n",
    "- for gradient computation and visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compute gradients\n",
    "gradx = correlate2d(zz, kernel, mode='same')\n",
    "grady = correlate2d(zz, kernel.T, mode='same')\n",
    "\n",
    "ang, mag = u.UV2angMag(gradx, grady)\n",
    "\n",
    "gradfield = hv.VectorField((xs, ys, ang, mag)).opts(vfield_opts)\n",
    "gradmag_img = hv.Image( (xs,ys,np.abs(mag)), group='grad', label='t0' ).opts(img_opts).opts(xlim=xrange, ylim=yrange)\n",
    "\n",
    "overlay = datashade(zz0_img, cmap=GnBu9) * zz0_contour * gradfield + gradmag_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio as iio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = iio.imread('../data/test/gradient.jpg')\n",
    "bounds\n",
    "print(test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = np.meshgrid(range(test_img.shape[1]), range(test_img.shape[0]))\n",
    "test_x.shape, test_y.shape\n",
    "# hv.RGB(test_img. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,g,b = np.dsplit(test_img, test_img.shape[-1])\n",
    "bounds = (0, 0, test_x.shape[1], test_x.shape[0])\n",
    "(\n",
    "    hv.Image( r.squeeze(), bounds=bounds)\n",
    "    +  hv.Image( g.squeeze(), bounds=bounds)\n",
    "    +  hv.Image( b.squeeze(), bounds=bounds)\n",
    ").cols(1).opts(\n",
    "    opts.Image(height=test_x.shape[0], width=test_x.shape[1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vec2 as vec2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurveSimulator(param.Parameterized):\n",
    "\n",
    "    n_steps = param.Integer(label='Number of simulation steps', default=100)\n",
    "    p = param.ObjectSelector(label='p', default=0., objects=np.linspace(0,1,num=n_steps.default))\n",
    "    reset = param.Action(lambda x: x.reset_handler(), doc=\"Click to clear the buffer and reset p\")\n",
    "    t_interval = param.Number(label='t_interval', doc='Time interval between plotting two points',\n",
    "                              softbounds=(0., 5.),\n",
    "                              default=0.)\n",
    "\n",
    "    \n",
    "    ################################################################################\n",
    "    # Constant class properties\n",
    "    ################################################################################\n",
    "    H,W = 500,500\n",
    "    curve_opts = opts.Points(size=5,width=W, height=H, \n",
    "                             xlim=(-1,1), ylim=(-1,1),\n",
    "                             color=dim('p')*256-50,\n",
    "                             tools=['hover']\n",
    "                            )\n",
    "    xopts = opts.Points('XCoord', width=W, height=H, size=5, xlim=(0,1), \n",
    "                        padding=0.1, invert_axes=True, invert_yaxis=True)\n",
    "    yopts = opts.Points('YCoord', width=W, height=H, size=5, xlim=(0,1), padding=0.1, invert_xaxis=True)\n",
    "    \n",
    "    \n",
    "    ################################################################################\n",
    "    # Parameter Dependencies\n",
    "    ################################################################################    \n",
    "    @param.depends('n_steps', watch=True)\n",
    "    def _update_p(self):\n",
    "        self.count['p'] += 1\n",
    "        self.param['p'].objects = np.linspace(0,1,num=self.n_steps)\n",
    "        print('updated p with new number of simulation steps: ', self.n_steps)\n",
    "    \n",
    "    @param.depends('p', watch=True)\n",
    "    def send_point(self):\n",
    "        point = pd.DataFrame([(self.p, *self.cfunc(self.p))], columns=['p','x','y'])\n",
    "        self.data_src.emit(point)\n",
    "        time.sleep(self.t_interval)\n",
    "        \n",
    "    def reset_handler(self):\n",
    "        self.set_param(p=0.0)\n",
    "        self.dfstream.clear()\n",
    "\n",
    "        \n",
    "    ################################################################################\n",
    "    # Initialization\n",
    "    ################################################################################\n",
    "    def __init__(self, cfunc, n_steps=100, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - cfunc (function): given an input of a float p in [0,1], returns (x,y), a \n",
    "        tuple of x and y coords\n",
    "        \n",
    "        - n_steps (int): number of simulation steps along the range of [0,1] for \n",
    "        the parameter, p\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs) # this is super important\n",
    "        self.cfunc = cfunc \n",
    "        self.n_steps = n_steps\n",
    "        \n",
    "        self.example = pd.DataFrame({'p': [], 'x':[], 'y':[]})\n",
    "        self.data_src = streamz.dataframe.DataFrame(example=self.example)\n",
    "        self.dfstream = Buffer(self.data_src, length=min(self.n_steps, 100), index=False)\n",
    "        self.set_dmap_curve()\n",
    "        self.set_dmap_x()\n",
    "        self.set_dmap_y()\n",
    "        self.overlay = (self.dmap_curve + self.dmap_y + self.dmap_x).cols(2)\n",
    "    \n",
    "\n",
    "    def set_dmap_curve(self):\n",
    "        dmap_curve = hv.DynamicMap(\n",
    "            lambda data: hv.Points(data, kdims=['x','y'], group='Curve'),\n",
    "            streams=[self.dfstream])#.opts(color='p')\n",
    "        self.dmap_curve = dmap_curve.opts(self.curve_opts)\n",
    "        \n",
    "    def set_dmap_x(self):\n",
    "        dmap_x = hv.DynamicMap(\n",
    "            lambda data: hv.Points( data, kdims=['p','x'], group='XCoord'),\n",
    "            streams=[self.dfstream]).opts(color='p')\n",
    "        self.dmap_x = dmap_x.opts(self.xopts)\n",
    "        \n",
    "    def set_dmap_y(self):\n",
    "        dmap_y = hv.DynamicMap(\n",
    "            lambda data: hv.Points( data, kdims=['p','y'], group='YCoord'),\n",
    "            streams=[self.dfstream]).opts(color='p')\n",
    "        self.dmap_y = dmap_y.opts(self.yopts)\n",
    "    \n",
    "    \n",
    "    ################################################################################\n",
    "    # Display DynammicMaps\n",
    "    ################################################################################ \n",
    "    def viewable(self):\n",
    "        return self.overlay\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define curve function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfunc = lambda p: np.sin(2*np.pi*p)\n",
    "yfunc = lambda p: np.cos(2*np.pi*p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different functions\n",
    "xfunc = lambda p: np.sin(2*np.pi*p)**2\n",
    "yfunc = lambda p: np.cos(2*np.pi*p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfunc = lambda p: np.sin(2*np.pi*p)**10\n",
    "yfunc = lambda p: np.cos(2*np.pi*p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternating along a straight line \n",
    "xfunc = lambda p: np.sin(2*np.pi*p)**2\n",
    "yfunc = lambda p: np.cos(2*np.pi*p)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't have to choose a periodic function\n",
    "xfunc = lambda p: np.log(p)\n",
    "yfunc = lambda p: p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something happens at p=0.5\n",
    "xfunc = lambda p: np.sin(2*np.pi*p**2)*p**3\n",
    "yfunc = lambda p: np.sin(np.pi*p**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the simulator for the curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfunc = lambda p: (xfunc(p), yfunc(p))\n",
    "c = CurveSimulator(cfunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Row(\n",
    "    pn.Param(c.param, width=500, widgets={\n",
    "        'p': pn.widgets.DiscretePlayer,\n",
    "        'reset': pn.widgets.Button(name=c.param['reset'].label),\n",
    "        't_interval': pn.widgets.FloatSlider\n",
    "    }),\n",
    "    pn.panel(c.viewable())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.dfstream.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:earthml_v2]",
   "language": "python",
   "name": "conda-env-earthml_v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
