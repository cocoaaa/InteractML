{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified: Jul 31, 2019\n",
    "\n",
    "# Evolution of curves using SDF\n",
    "\n",
    "- Define a step function that encodes the discrete PDF of the curve evolution \n",
    "- Visualize the contour lines (at zero level)\n",
    "- Active Contour \n",
    "    - satellite images\n",
    "    - biomedical images\n",
    "- Next step: \n",
    "    - agent-based clustering for image segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, time\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.signal import correlate2d\n",
    "import pandas as pd\n",
    "    \n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "p = print\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "import pdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "# Don't generate bytecode\n",
    "sys.dont_write_bytecode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import xarray as xr\n",
    "\n",
    "from holoviews import opts, dim\n",
    "from holoviews.operation.datashader import datashade, shade, dynspread, rasterize\n",
    "from holoviews.streams import Stream, param\n",
    "from holoviews import streams\n",
    "import geoviews as gv\n",
    "import geoviews.feature as gf\n",
    "from geoviews import tile_sources as gvts\n",
    "\n",
    "import panel as pn\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "\n",
    "hv.notebook_extension('bokeh')\n",
    "hv.Dimension.type_formatters[np.datetime64] = '%Y-%m-%d'\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the utils directory to the search path\n",
    "UTILS_DIR = Path('../utils').absolute()\n",
    "assert UTILS_DIR.exists()\n",
    "if str(UTILS_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(UTILS_DIR))\n",
    "    print(f\"Added {str(UTILS_DIR)} to sys.path\")\n",
    "\n",
    "# pp(sys.path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_mro as mro, nprint, timeit\n",
    "import utils\n",
    "\n",
    "import sdfs \n",
    "from vector import Vector as vec\n",
    "from samples import LSTestSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calculus as calc\n",
    "from grid import CartesianGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set visualization options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = 500,500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.defaults(\n",
    "    opts.Image(colorbar=True, active_tools=['wheel_zoom'], tools=['hover']),\n",
    "    opts.Curve(tools=['hover'], active_tools=['wheel_zoom']),\n",
    "    opts.RGB(active_tools=['wheel_zoom'], tools=['hover'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_opts = opts.Image(height=H, width=W, colorbar_position='bottom')\n",
    "vfield_opts = opts.VectorField(width=W, height=H, color='Magnitude',\n",
    "#                                magnitude=dim('Magnitude').norm()*0.2,\n",
    "                               pivot='tip',\n",
    "                               rescale_lengths=True)\n",
    "curve_opts = opts.Points(size=5,width=W, height=H, padding=0.1, \n",
    "#                             xlim=(-10,10), ylim=(-10,10),\n",
    "#                         color=dim('p')*256-50\n",
    "                        )\n",
    "contour_opts = opts.Contours(width=W, height=H, \n",
    "                             colorbar=False, \n",
    "                             tools=['hover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab registered bokeh renderer\n",
    "print(\"Currently available renderers: \", *hv.Store.renderers.keys())\n",
    "renderer = hv.renderer('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Curve Evolution \n",
    "\n",
    "Todo\n",
    "- [ ] Finite Difference method on parametric equations\n",
    "- [ ] Levelset functions\n",
    "    - 2D signed distance functions: [src](https://is.gd/t7p5mk)\n",
    "- [ ] Active contour on satellite images\n",
    "- [ ] Agent-based modelling with specified rules\n",
    "    - satellite image segmentation (~ clustering based on local features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Front Propagation \n",
    "Refer to Equation 4.8 and 4.20\n",
    "\n",
    "1. Spatial gradient computation </br>\n",
    "For stability in computing the spatial gradients, use Eqn. 4.33\n",
    "\n",
    "2. Temporal discretization </br>\n",
    "To propagate the front over time, we neet to update the levelset values over time \n",
    "according to a process. We express the process as a partial differential of the levelset function $\\phi$ wrt time:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\phi}{\\partial t} (t)= L(t, \\phi(t)), ~~~~~ \\phi(t_0) = \\phi^{0}\n",
    "$$\n",
    "\n",
    "where $L$ represents a general function that depends on time stamp $t$ and the levelset function itself.\n",
    "Given $L$ and the initial condition $\\phi_{0}$, our goal is to find $\\phi(t_{1}), \\phi(t_{2})$, ... $\\phi(t_{n})$ This process is called **\"time integration''**, as we are solving the partial differential equation wrt time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the first-order Taylor expansion around $t + \\Delta t$, we derive a \"forward\" Euler time integration equation for discretely sampled levelset:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\phi(t+\\Delta t) &\\approx \\phi(t) + \\Delta t \\frac{\\partial \\phi}{\\partial t}(t) \\\\\n",
    "                 &\\approx \\phi(t) + \\Delta t L(t, \\phi(t))\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equations we have described both in a continous and discretized domain for $\\phi(t)$ hold for any $\\phi$, and is not specificed to a levelset function.  In that respect, a better notation to express this generality, I should have used a symbol that is not $\\phi$, oops. But, we are interested in the levelset functions (in particular a discretly sampled one), so from here on, we will view this general equation from the perspective of time integration for a levelset equation.  That means, $\\phi$ refers to the levelset function, and $L$, which describes how the levelset fucntion changes over time, correpsonds to the speed function $F$ in the fundamental levelset form. Recall this speed function is the speed in direction normal to the levelset function (at all levels).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two ways to view the fundamental levelset formulation\n",
    "1. Advection: floating surface in an external vectorfield/flow $\\vec{V}$\n",
    "\n",
    "\n",
    "2. Motion of a front in normal direction according to a given speed $F$ </br>\n",
    "The front propagates in its normal direction with a given speed $F(t, \\phi)$\n",
    "\n",
    "The two views are mathmatically equivalent as can be shown by using the equality that links the external vector field point of view to the levelset domain by linking the way to compute normal vector in both domains:\n",
    "\n",
    "$$\n",
    "\\vec{n}(\\vec{x}) = \\frac{\\vec{\\nabla}\\phi (\\vec{x})}{\\lVert \\vec{\\nabla}\\phi (\\vec{x}) \\rVert}\n",
    "$$\n",
    "\n",
    "where $\\vec{x}$ refers to a point in the embedding space. In 2Dim case (ie. for curve evolution), we can express this point with two Cartian coordinates $(x,y)$:\n",
    "\n",
    "$$\n",
    "\\vec{n}(x,y) = \\frac{\\vec{\\nabla}\\phi (x,y)}{\\lVert \\vec{\\nabla}\\phi (x,y) \\rVert}\n",
    "$$\n",
    "\n",
    "The key point of this equality is that it proves the two ways to view the fundamental levelset form are mathmatically equivalent. Nevertheless, their physical meanings are distinct, and we solve the equations differently when it comes to finding the computational solutions, ie. $\\phi(t_{1}),\\phi(t_{2}), \\dots$.\n",
    "\n",
    "The solution to the first approach (ie. advection) will be implemented in `LSEvolver.advect` method. \n",
    "The solution to the second approach (ie. front's normal motion) will be implemented in `LSEvolver. propagate` method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on to the impelemntation, let me express the time integration of a discrete levelset function for each perspective\n",
    "\n",
    "### continue here!! ###\n",
    "11:45am, Jul 31, 2019\n",
    "- plug in the V or F function to the time integration (discrete) - the one with \\approx -- \n",
    "###\n",
    "\n",
    "1. Advection\n",
    "\n",
    "\n",
    "2. Front's normal motion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to look at the implementation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "class LSEvolver(CartesianGrid):\n",
    "    \"\"\"\n",
    "    EvolvingLS: A levelSet evolution according to an initial-valued problem given by a PDE\n",
    "    \n",
    "    Args:\n",
    "    - F (callable): takes a LevelSet object and time index and returns a np array \n",
    "    with the same shape as the levelset's grid\n",
    "    \"\"\"\n",
    "    def __init__(self, xs, ys, data=None, t=0):\n",
    "        super().__init__(xs, ys, data)\n",
    "        \n",
    "        self.time = t #current time\n",
    "        self.delta = np.inf # average change of LS function values between consecutive time stamps\n",
    "            \n",
    "    def run(self, F, dt, pde_class, threshold=1e-3, maxIter=1e4):\n",
    "        count = 0\n",
    "        deltas = []\n",
    "        phis = {}\n",
    "        while self.delta > threshold:\n",
    "            if count > maxIter: \n",
    "                print(\"MaxIter reached: \", count)\n",
    "                break\n",
    "            self.propagate(F,dt,pde_class)\n",
    "            deltas.append(self.delta)\n",
    "            count += 1\n",
    "            if count%1000:\n",
    "                phis[self.time] = self.data\n",
    "        print(f\"Ran for {count} steps, for {self.time} periods\")\n",
    "        print(f\"\\taverage delta phi: {self.delta}\")\n",
    "        return deltas, phis\n",
    "\n",
    "    def propagate(self, F, dt, pde_class):\n",
    "        \"\"\"\n",
    "        Equation 4.8 and 4.20\n",
    "        1. Spatial gradient computation\n",
    "        For stability in computing the spatial gradients, use Eqn. 4.33\n",
    "        \n",
    "        2. Temporal discretization\n",
    "        To propagate the front over time, we neet to update the levelset values over time \n",
    "        according to a process. We express the process as a partial differential of the levelset \n",
    "        function (\\phi) wrt time:\n",
    "        \n",
    "        \\frac\n",
    "        \n",
    "        Our goal is to find \\phi(t1), \\phi(t2), ... given a initial \\phi(t0)\n",
    "        equatation\n",
    "        This process is called \"time integration\" \n",
    "        \n",
    "        Args:\n",
    "        - pde_class (str): 'hyperbolic', 'parabolic'\n",
    "            * (1) if F depends on at most order 1 derivatives of the levelset function phi \n",
    "            wrt space and time, the information propagation has a specific direction \n",
    "            (ie. \"characteristics\"), and we need to be careful about which gradient to \n",
    "            take -- backward, forward.  In this case, the levelset equation is 'hyperbolic', \n",
    "            which is a subclass of Hamilton-Jacobian equation. \n",
    "            \n",
    "            * (2) if F depends on derivatives of order >= 2 (eg. F = alpha*curvature),\n",
    "            then the information propagates from all directions, and we can use the \n",
    "            central finite difference method to compute the spatial gradients.\n",
    "        \"\"\"\n",
    "        if dt > min(self.dx, self.dy):\n",
    "            #todo: print error but then make dt smaller smartly\n",
    "            raise ValueError('dt should be smaller than x and y sample resolutions: ', dt)\n",
    "                \n",
    "        assert pde_class in ['hyperbolic','parabolic'], \\\n",
    "        f\"pde_class must be either 1 or 2: {pde_class}\"\n",
    "        \n",
    "        if pde_class == 'hyperbolic':\n",
    "            dxb, dxf, dyb, dyf = self.get_diff1_bf()\n",
    "            debug = (\n",
    "                hv.Image(self.data, label='phi') + hv.Image([])\n",
    "                + hv.Image(dxb, label='dx back') + hv.Image(dxf, label='dx forward')\n",
    "                + hv.Image(dyb, label='dy back') + hv.Image(dyf, label='dy forward')\n",
    "            ).cols(2)\n",
    "            display(debug)\n",
    "\n",
    "            S = np.sign(F)\n",
    "            dx = np.maximum(S*dxb, -S*dxf)\n",
    "            dy = np.maximum(S*dyb, -S*dyf)\n",
    "\n",
    "            dmag = np.sqrt(dx**2 + dy**2)\n",
    "            \n",
    "        else :#pde_class == 'parabolic':\n",
    "            dx,dy = self.get_diff1_central()\n",
    "            dmag = comput_mag(dx,dy)# todo\n",
    "        \n",
    "        \n",
    "        # update phi\n",
    "        dphi = dt* dmag * F\n",
    "        self.delta = dphi.sum() / dphi.size\n",
    "        self.data -= dphi \n",
    "        \n",
    "        # update time\n",
    "        self.time += dt\n",
    "        \n",
    "    def advect(self, V, dt):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - V (ndarray of shape (w,h,2)): containing x and y component of the vector field\n",
    "        - dt (float): time step size\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def reinit(self, method='sweep'):\n",
    "        \"\"\"\n",
    "        Reset current phi values (in self.data) to satisfy Eikonal equality\n",
    "        in Eqn. 4.12\n",
    "        \n",
    "        - method \n",
    "            - 'pde': solve eqn. 4.37 with current phi data, until steady state\n",
    "            - 'fmm': fast marching method\n",
    "            - 'sweep' (default): paper [88]\n",
    "            - 'exact': paper [64]\n",
    "            \n",
    "            Default is 'sweep'\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def get_diff1_bf(self, switch=True):\n",
    "        dxb, dxf, dyb, dyf = calc.diff1_bf(self.data, switch)\n",
    "        return dxb/self.dx, dxf/self.dx, dyb/self.dy, dyf/self.dy\n",
    "    \n",
    "    def get_diff1_central(self):\n",
    "        dx, dy= calc.diff1_central(self.data)\n",
    "        return dx/(2*self.dx), dy/(2*self.dy)\n",
    "    \n",
    "    def get_curvature(self):\n",
    "        return curvature(self.data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test LSEvolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aiviz]",
   "language": "python",
   "name": "conda-env-aiviz-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
