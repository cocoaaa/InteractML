{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified: Jul 31, 2019\n",
    "\n",
    "# Evolution of curves using SDF\n",
    "\n",
    "- Define a step function that encodes the discrete PDF of the curve evolution \n",
    "- Visualize the contour lines (at zero level)\n",
    "- Active Contour \n",
    "    - satellite images\n",
    "    - biomedical images\n",
    "- Next step: \n",
    "    - agent-based clustering for image segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, time\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.signal import correlate2d\n",
    "import pandas as pd\n",
    "    \n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "p = print\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "import pdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "# Don't generate bytecode\n",
    "sys.dont_write_bytecode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import xarray as xr\n",
    "\n",
    "from holoviews import opts, dim\n",
    "from holoviews.operation.datashader import datashade, shade, dynspread, rasterize\n",
    "from holoviews.streams import Stream, param\n",
    "from holoviews import streams\n",
    "import geoviews as gv\n",
    "import geoviews.feature as gf\n",
    "from geoviews import tile_sources as gvts\n",
    "\n",
    "import panel as pn\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "\n",
    "hv.notebook_extension('bokeh')\n",
    "hv.Dimension.type_formatters[np.datetime64] = '%Y-%m-%d'\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the utils directory to the search path\n",
    "UTILS_DIR = Path('../utils').absolute()\n",
    "assert UTILS_DIR.exists()\n",
    "if str(UTILS_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(UTILS_DIR))\n",
    "    print(f\"Added {str(UTILS_DIR)} to sys.path\")\n",
    "\n",
    "# pp(sys.path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_mro as mro, nprint, timeit\n",
    "import utils\n",
    "\n",
    "import sdfs \n",
    "from samples import LSTestSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calculus as calc\n",
    "from grid import CartesianGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set visualization options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = 500,500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.defaults(\n",
    "    opts.Image(colorbar=True, active_tools=['wheel_zoom'], tools=['hover'],\n",
    "              width=W, height=H, aspect='equal'),\n",
    "    opts.Curve(tools=['hover'], active_tools=['wheel_zoom'],\n",
    "              width=W, height=H, aspect='equal'),\n",
    "    opts.RGB(active_tools=['wheel_zoom'], tools=['hover'],\n",
    "            width=W, height=H)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_opts = opts.Image(height=H, width=W, colorbar_position='bottom')\n",
    "vfield_opts = opts.VectorField(width=W, height=H, color='Magnitude',\n",
    "#                                magnitude=dim('Magnitude').norm()*0.2,\n",
    "                               pivot='tip',\n",
    "                               rescale_lengths=True)\n",
    "curve_opts = opts.Points(size=5,width=W, height=H, padding=0.1, \n",
    "#                             xlim=(-10,10), ylim=(-10,10),\n",
    "#                         color=dim('p')*256-50\n",
    "                        )\n",
    "contour_opts = opts.Contours(width=W, height=H, \n",
    "                             colorbar=False, \n",
    "                             tools=['hover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab registered bokeh renderer\n",
    "print(\"Currently available renderers: \", *hv.Store.renderers.keys())\n",
    "renderer = hv.renderer('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Curve Evolution \n",
    "\n",
    "Todo\n",
    "- [ ] Finite Difference method on parametric equations\n",
    "- [ ] Levelset functions\n",
    "    - 2D signed distance functions: [src](https://is.gd/t7p5mk)\n",
    "- [ ] Active contour on satellite images\n",
    "- [ ] Agent-based modelling with specified rules\n",
    "    - satellite image segmentation (~ clustering based on local features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Front Propagation \n",
    "Refer to Equation 4.8 and 4.20\n",
    "\n",
    "1. Spatial gradient computation </br>\n",
    "For stability in computing the spatial gradients, use Eqn. 4.33\n",
    "\n",
    "2. Temporal discretization </br>\n",
    "To propagate the front over time, we neet to update the levelset values over time \n",
    "according to a process. We express the process as a partial differential of the levelset function $\\phi$ wrt time:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\phi}{\\partial t} (t)= L(t, \\phi(t)), ~~~~~ \\phi(t_0) = \\phi^{0}\n",
    "$$\n",
    "\n",
    "where $L$ represents a general function that depends on time stamp $t$ and the levelset function itself.\n",
    "Given $L$ and the initial condition $\\phi_{0}$, our goal is to find $\\phi(t_{1}), \\phi(t_{2})$, ... $\\phi(t_{n})$ This process is called **\"time integration''**, as we are solving the partial differential equation wrt time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the first-order Taylor expansion around $t + \\Delta t$, we derive a \"forward\" Euler time integration equation for discretely sampled levelset:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\phi(t+\\Delta t) &\\approx \\phi(t) + \\Delta t \\frac{\\partial \\phi}{\\partial t}(t) \\\\\n",
    "                 &\\approx \\phi(t) + \\Delta t L(t, \\phi(t))\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equations we have described both in a continous and discretized domain for $\\phi(t)$ hold for any $\\phi$, and is not specificed to a levelset function.  In that respect, a better notation to express this generality, I should have used a symbol that is not $\\phi$, oops. But, we are interested in the levelset functions (in particular a discretly sampled one), so from here on, we will view this general equation from the perspective of time integration for a levelset equation.  That means, $\\phi$ refers to the levelset function, and $L$, which describes how the levelset fucntion changes over time, correpsonds to the speed function $F$ in the fundamental levelset form. Recall this speed function is the speed in direction normal to the levelset function (at all levels).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two ways to view the fundamental levelset formulation\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\phi}{\\partial{t}} &= -\\nabla{\\phi} \\cdot \\vec{V}  \\label{eq:4.7}  \\tag{4.7} \\\\\n",
    "                                  &= -\\lVert \\vec{\\nabla} \\phi \\rVert F(\\vec{x}, \\vec{n}, \\phi, \\dots )\n",
    "                                     \\label{eq:4.8}  \\tag{4.8} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "1. Advection: floating surface in an external vectorfield/flow $\\vec{V}$\n",
    "\n",
    "\n",
    "2. Motion of a front in normal direction according to a given speed $F$ </br>\n",
    "The front propagates in its normal direction with a given speed $F(t, \\phi)$\n",
    "\n",
    "The two views are mathmatically equivalent as can be shown by using the equality that links the external vector field point of view to the levelset domain by linking the way to compute normal vector in both domains:\n",
    "\n",
    "$$\n",
    "\\vec{n}(\\vec{x}) = \\frac{\\vec{\\nabla}\\phi (\\vec{x})}{\\lVert \\vec{\\nabla}\\phi (\\vec{x}) \\rVert}\n",
    "$$\n",
    "\n",
    "where $\\vec{x}$ refers to a point in the embedding space. In 2Dim case (ie. for curve evolution), we can express this point with two Cartian coordinates $(x,y)$:\n",
    "\n",
    "$$\n",
    "\\vec{n}(x,y) = \\frac{\\vec{\\nabla}\\phi (x,y)}{\\lVert \\vec{\\nabla}\\phi (x,y) \\rVert}\n",
    "$$\n",
    "\n",
    "The key point of this equality is that it proves the two ways to view the fundamental levelset form are mathmatically equivalent. Nevertheless, their physical meanings are distinct, and we solve the equations differently when it comes to finding the computational solutions, ie. $\\phi(t_{1}),\\phi(t_{2}), \\dots$.\n",
    "\n",
    "The solution to the first approach (ie. advection) will be implemented in `LSEvolver.advect` method. \n",
    "The solution to the second approach (ie. front's normal motion) will be implemented in `LSEvolver. propagate` method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on to the implementation, let me summaruize the time integration of a discrete levelset function for each perspective. Note that superscipts are used to indicate the time steps.\n",
    "\n",
    "1. Advection\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "             \\frac{\\partial \\phi}{\\partial{t}} &=& -\\nabla{\\phi} \\cdot \\vec{V}  \\label{eq:4.7}  \\tag{4.7} \\\\\n",
    "\\Rightarrow  \\phi^{t + \\Delta t} &=& \\phi^{t} - \\Delta t ( \\vec{\\nabla} \\phi^{t} \\cdot \\vec{V^{t}} ) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "2. Front's normal motion\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\phi}{\\partial{t}} &=& -\\lVert \\vec{\\nabla} \\phi \\rVert F(\\vec{x}, \\vec{n}, \\phi, \\dots )\n",
    "                                     \\label{eq:4.8}  \\tag{4.8} \\\\\n",
    "\\Rightarrow  \\phi^{t+\\Delta t} &=& \\phi^{t} - \\Delta t \\lVert \\vec{\\nabla} \\phi^{t} \\rVert F^{t} \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common examples of the speed function ( $F^{t}$)\n",
    "- constant: $F^{t} = 1 ~~ \\forall t$,  where the domain of every $F^{t}$ is $\\{ \\vec{x} \\in \\Gamma(t) \\}$\n",
    "\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\phi^{t+\\Delta t} &=& \\phi^{t} - \\Delta t \\lVert \\vec{\\nabla} \\phi^{t} \\rVert \\cdot 1\n",
    "    \\end{align}\n",
    "    $$\n",
    "    \n",
    "- smoothing motion: $F^{t} = 1-\\alpha \\kappa$ where $\\kappa$ is the curvature of the front\n",
    "    - has an effect of regularizing the front (ie. curve in 2 dim case)\n",
    "    \n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\phi^{t+\\Delta t} &=& \\phi^{t} - \\Delta t \\lVert \\vec{\\nabla} \\phi^{t} \\rVert \\cdot (1-\\alpha \\kappa(\\phi^{t})\n",
    "    \\end{align}\n",
    "    $$\n",
    "    \n",
    "Note $F$ is independent of $t$ in both cases, which means the form of the $F$ stays the same across the entire\n",
    "propagation process. That doesn't mean the exact values at $t_1$ and $t_2$ are the same though. Specifically, this implies that we need to compute $\\kappa$ at each step, based on the current time's $\\phi$ since $\\kappa$ is a function of a levelset which is dynamically evolving over time, ie. $\\phi$ has a dependency on time variable $t$.\n",
    "\n",
    "Another comment worth mentioning here is that the first example of constant speed function $F=1$ and the second case where $F$ depends on the curvature belong to different PDE categories. The first case is known as \"hyperbolic\" which is a case of \"Hamilton-Jacobian equation\", and the second case belongs to \"parabolic\" equation.  The criterion to category them into these different PDE classes is the order of derivatives that $F$ is dependent on. \n",
    "\n",
    "- hyperbolic: $F$ depends on at most order $1$ derivative\n",
    "    - eg: $F=1$, $F=\\lVert \\vec{\\nabla} \\phi^{t} \\rVert$\n",
    "    - the front propagation has a directionality (aka. characteristics of the PDE) </br>\n",
    "    $\\Rightarrow$ we need to be careful which spatial gradient to take (forward or backward)\n",
    "    \n",
    "    \n",
    "- parabolic: $F$ depends on derivatives of order greater than $1$\n",
    "    - eg: $F= \\alpha \\kappa$ \n",
    "    - Information related to the current spatial location ($\\vec{x}$) comes from all directions </br>\n",
    "    $\\Rightarrow$ one way to encompass this trait is to use central difference in computing spatial gradients\n",
    "    \n",
    "![advection-update](../assets/update_advection_bw.jpg)\n",
    "![propagation-update](../assets/update_front_propagation_bw.jpg)\n",
    "\n",
    "\n",
    "We will show how these speed functions affect the front propagation behaviors in laster sections.\n",
    "For now, we are ready to jump into the implementation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Modified: Jul 31, 2019 \n",
    "## todo:\n",
    "est: ~~30mins~~ 3days?....?\n",
    "- [x] check i,j -> c,r conversion\n",
    "- [x] ~~incorporate Grid as a data storage (self.grid) of LevelSet class~~ make LSEvolver as a subclass of CartesianGrid\n",
    "- [x] get a list of points from holoviews polydraw\n",
    "- [ ] make a list of line segments from the point list\n",
    "- [ ] for each line segment, make Line2d object and get polygon for the band box\n",
    "- [ ] collect the band bbox points into all list, also \n",
    "- [ ] show in holoview with the linesegments and its bands\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "class LSEvolver(CartesianGrid):\n",
    "    \"\"\"\n",
    "    Levelset propagator: A levelSet evolution solved by discrete time integration\n",
    "    of a PDE with a given initial levelset function, \\phi(t=0). \n",
    "    \"\"\"\n",
    "    def __init__(self, xs, ys, data=None, t=0):\n",
    "        super().__init__(xs, ys, data)\n",
    "        \n",
    "        self.time = t #current time\n",
    "        self.delta = np.inf # average change of LS function values between consecutive time stamps\n",
    "        \n",
    "    @timeit        \n",
    "    def run(self, F, dt, pde_class, threshold=1e-3, maxIter=1e2, collect_every=50):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - F (2d ndarray): same shape as self.data or broadcastable to self.data's shape(eg. a constant)\n",
    "        - dt (flaot): time sampling period in continuous levelset space\n",
    "        - pde_class (str): 'hyperbolic' or 'parabolic'\n",
    "        - threshold (float): propagation stopping criterion based on the average change in consecutive phi values \n",
    "        - maxIter (int): maximum number of iterations for the propagate steps. This takes precedence over the threshold\n",
    "        - collect_every (int): interval between collecting the levelset values for visualizing the process\n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        deltas = {}\n",
    "        phis = {}\n",
    "        while self.delta > threshold:\n",
    "            if count > maxIter: \n",
    "                print(\"MaxIter reached: \", count)\n",
    "                break\n",
    "            self.propagate(F, dt, pde_class, debug=False)\n",
    "            deltas[self.time] = self.delta\n",
    "            count += 1\n",
    "            if count%collect_every == 0:\n",
    "                print(f\"Running {count}th iteration\")\n",
    "                phis[self.time] = self.data.copy()\n",
    "                \n",
    "        print(f\"Ran for {count} steps, for total {self.time} periods\")\n",
    "        print(f\"\\taverage delta phi: {self.delta}\")\n",
    "        return deltas, phis\n",
    "\n",
    "    def propagate(self, F, dt, pde_class, debug=False):\n",
    "        \"\"\"\n",
    "        Equation 4.8 and 4.20\n",
    "        1. Spatial gradient computation\n",
    "        For stability in computing the spatial gradients, use Eqn. 4.33\n",
    "        \n",
    "        2. Temporal discretization\n",
    "        To propagate the front over time, we neet to update the levelset values over time \n",
    "        according to a process. We express the process as a partial differential of the levelset \n",
    "        function (\\phi) wrt time:\n",
    "        \n",
    "        \\frac\n",
    "        \n",
    "        Our goal is to find \\phi(t1), \\phi(t2), ... given a initial \\phi(t0)\n",
    "        equatation\n",
    "        This process is called \"time integration\" \n",
    "        \n",
    "        Args:\n",
    "        - pde_class (str): 'hyperbolic', 'parabolic'\n",
    "            * (1) if F depends on at most order 1 derivatives of the levelset function phi \n",
    "            wrt space and time, the information propagation has a specific direction \n",
    "            (ie. \"characteristics\"), and we need to be careful about which gradient to \n",
    "            take -- backward, forward.  In this case, the levelset equation is 'hyperbolic', \n",
    "            which is a subclass of Hamilton-Jacobian equation. \n",
    "            \n",
    "            * (2) if F depends on derivatives of order >= 2 (eg. F = alpha*curvature),\n",
    "            then the information propagates from all directions, and we can use the \n",
    "            central finite difference method to compute the spatial gradients.\n",
    "        \"\"\"\n",
    "        assert pde_class in ['hyperbolic','parabolic'], f\"pde_class must be either 1 or 2: {pde_class}\"\n",
    "        \n",
    "        if pde_class == 'hyperbolic':\n",
    "            dxb, dxf, dyb, dyf = self.get_diff1_bf()\n",
    "            \n",
    "            if debug:\n",
    "                overlay = (\n",
    "                    hv.Image(self.data, label='phi') + hv.Image([])\n",
    "                    + hv.Image(dxb, label='dx back') + hv.Image(dxf, label='dx forward')\n",
    "                    + hv.Image(dyb, label='dy back') + hv.Image(dyf, label='dy forward')\n",
    "                ).cols(2)\n",
    "                display(overlay)\n",
    "\n",
    "            S = np.sign(F)\n",
    "            dx = np.maximum(S*dxb, -S*dxf)\n",
    "            dy = np.maximum(S*dyb, -S*dyf)\n",
    "            \n",
    "        else: #pde_class == 'parabolic':\n",
    "            dx,dy = self.get_diff1_central()\n",
    "\n",
    "        dmag = np.sqrt(dx**2 + dy**2)\n",
    "    \n",
    "        # update phi\n",
    "        dphi = dt * dmag * F\n",
    "        self.data -= dphi \n",
    "        self.delta = dphi.sum() / dphi.size\n",
    "\n",
    "        # update time\n",
    "        self.time += dt\n",
    "\n",
    "        \n",
    "    def advect(self, V, dt):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - V (ndarray of shape (w,h,2)): containing x and y component of the vector field\n",
    "        - dt (float): time step size\n",
    "        \"\"\"\n",
    "        if dt > min(self.dx, self.dy):\n",
    "            #todo: print error but then make dt smaller smartly\n",
    "            raise ValueError('dt should be smaller than x and y sample resolutions: ', dt)\n",
    "        pass\n",
    "    \n",
    "    def reinit(self, method='sweep'):\n",
    "        \"\"\"\n",
    "        Reset current phi values (in self.data) to satisfy Eikonal equality\n",
    "        in Eqn. 4.12\n",
    "        \n",
    "        - method \n",
    "            - 'pde': solve eqn. 4.37 with current phi data, until steady state\n",
    "            - 'fmm': fast marching method\n",
    "            - 'sweep' (default): paper [88]\n",
    "            - 'exact': paper [64]\n",
    "            \n",
    "            Default is 'sweep'\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def get_diff1_bf(self, switch=True):\n",
    "        dxb, dxf, dyb, dyf = calc.diff1_bf(self.data, switch)\n",
    "        return dxb/self.dx, dxf/self.dx, dyb/self.dy, dyf/self.dy\n",
    "    \n",
    "    def get_diff1_central(self):\n",
    "        dx, dy= calc.diff1_central(self.data)\n",
    "        return dx/(2*self.dx), dy/(2*self.dy)\n",
    "    \n",
    "    def get_curvature(self):\n",
    "        return curvature(self.data)\n",
    "    \n",
    "    def satisfies_cfl(self, V, dt, method=\"euler1\"):\n",
    "        \"\"\"\n",
    "        todo: rename to validate_dt?\n",
    "        \n",
    "        Note: this is applicable only when you choose to 'advect' your front. \n",
    "        - irrelevant to 'propagate' method.\n",
    "        \n",
    "        Check if the given dt satisifes the CFL condition for the stability of Euler forward\n",
    "        time integration (ie. explicit method). In other words, this is to ensure the time \n",
    "        steps are small enough in comparison to the spatial sampling size (dx and dy) so that \n",
    "        the errors do not grow over time.\n",
    "        \n",
    "         $$ \\frac{V \\dot \\Delta t}{\\Delta x} < c $$\n",
    "         \n",
    "         where $c$ is the CFL-number which depends on the time integration method.\n",
    "         \n",
    "         In case of the explicit time integration method (eg. forward Euler and RK-schemes), \n",
    "         c = 1. Other cases (ie. for higher order methods), the c value can be very restrictive, \n",
    "         and it may be better to use an implicit time integration (eg. backward Euler)\n",
    "         \n",
    "         Args:\n",
    "         - V (3 dim np.ndarray): \n",
    "             - first channel has the x component of the external velocity field\n",
    "             - second channel has the y component of the external velocity field\n",
    "         - method (str): time integration method and order. \n",
    "             - currently supports only \"euler1\" which indicates \"first-order forward Euler\" \n",
    "        \"\"\"\n",
    "        if method is not \"euler1\":\n",
    "            raise ValueError(\"Currently only first-order forward euler method is supported\")\n",
    "        assert V.ndim == 3, f\"V should be three-dimensional: {V.ndim}\"\n",
    "        Vx, Vy = V[...,0], V[...,1]\n",
    "        \n",
    "        Vx_satisfies = np.all(Vx < dt/self.dx)\n",
    "        Vy_satisfies = np.all(Vy < dt/self.dx)\n",
    "        is_valid = Vx_satisfies and Vy_satisfies\n",
    "        if not is_valid:\n",
    "            Vmax = V.max()\n",
    "            dt = (min(self.dx, self.dy) / Vmax) - 1e-5\n",
    "        return (is_valid, dt)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test LSEvolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs,ys,zz = LSTestSample.centered_linear_grid()\n",
    "\n",
    "n_points = 100\n",
    "xlim = (-2,2)\n",
    "ylim = (-2,2)\n",
    "sdf = sdfs.sdUnitCircle\n",
    "xs = np.linspace(*xlim, n_points)\n",
    "ys = np.linspace(*ylim, n_points)[::-1]\n",
    "zz = sdfs.eval_sdf(xs, ys, sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = LSEvolver(xs,ys,zz)\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi0_img = hv.Image((xs,ys,zz)) \n",
    "front0 = hv.Image((xs,ys,np.isclose(zz,0)))\n",
    "contour0 = hv.operation.contours(phi0_img, levels=1).opts(contour_opts)\n",
    "# (phi0 + front0).opts(shared_axes=False)\n",
    "# (phi0_img * contour0 + front0).opts(shared_axes=False)\n",
    "\n",
    "## Intermediate results collection containers\n",
    "times = [ls.time]\n",
    "phis = {ls.time: ls.data.copy()}\n",
    "deltas = {ls.time: ls.delta}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    del tstep_widget, mdbox\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "F = 1\n",
    "dt = 1e-2\n",
    "pde_class='hyperbolic'\n",
    "maxIter = 500\n",
    "tstep_widget = pn.widgets.Player(start=0, end=maxIter, value=0, step=1)\n",
    "mdbox = pn.pane.Markdown('')\n",
    "\n",
    "# if tstep_widgets is redefined/resassigned, any parameterized function that depends on this widget's param value \n",
    "# must be deleted and then run the below\n",
    "try: \n",
    "    del step\n",
    "    del show_current_phi\n",
    "except NameError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pn.depends(tstep_widget.param.value)\n",
    "def step(value):\n",
    "    #show_current_phi()\n",
    "\n",
    "    \n",
    "    # Propagate one step \n",
    "    out = f\"\"\"##Step: {value}, time: {ls.time:.3f} -> {ls.time+dt:.3f}\n",
    "    Propagation started...\n",
    "    \"\"\"\n",
    "    mdbox.object =  out\n",
    "    ls.propagate(F,dt,pde_class)\n",
    "    mdbox.object += \"Propagation finished\\n\"\n",
    "    \n",
    "    # Record intermediate results\n",
    "    phis[ls.time] = ls.data.copy()\n",
    "    deltas[ls.time]=ls.delta\n",
    "    times.append(ls.time)\n",
    "    \n",
    "    img = hv.Image((ls.xs,ls.ys,ls.data), group='phi', label=f'time: {ls.time}').opts(img_opts)\n",
    "    contour = hv.operation.contours(img, levels=1).opts(contour_opts)\n",
    "    mdbox.object += \"Image updated\"\n",
    "    return img * contour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pn.Row(tstep_widget, mdbox, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls.time, ls.delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @pn.depends(tstep_widget.param.value)\n",
    "# def show_current_phi(*args, **kwargs):\n",
    "#     img = hv.Image((ls.xs,ls.ys,ls.data), group='phi', label=f'time: {ls.time}').opts(img_opts)\n",
    "#     contour = hv.operation.contours(img, levels=1).opts(contour_opts)\n",
    "#     return img * contour\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Row(\n",
    "    pn.Column(tstep_widget, mdbox),\n",
    "    step\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate while recording\n",
    "Another way is to simulate all at once for certain steps (either decided by the threshold value of delta or maxIter)\n",
    "and visualize the collected intermediate results after the simulation finishes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 100\n",
    "xlim = (-2,2)\n",
    "ylim = (-2,2)\n",
    "# sdf = sdfs.sdUnitCircle\n",
    "sdf = sdfs.sdStar1\n",
    "sdf_name = 'sdStar1'\n",
    "\n",
    "xs = np.linspace(*xlim, n_points)\n",
    "ys = np.linspace(*ylim, n_points)[::-1]\n",
    "zz = sdfs.eval_sdf(xs, ys, sdf)\n",
    "base = hv.Image((xs, ys, zz))\n",
    "\n",
    "    \n",
    "ls = LSEvolver(xs,ys,zz)\n",
    "F = 1\n",
    "dt = 1e-2\n",
    "pde_class = 'hyperbolic'\n",
    "collect_every = 10\n",
    "maxIter = 100\n",
    "threshold=1e-6\n",
    "# ls.propagate(F,dt,pde_class,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas, phis = ls.run(F, dt, pde_class, threshold=1e-6, maxIter=maxIter, collect_every=collect_every)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the intemediate phis and deltas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save computation results\n",
    "out_pkl = f'../data/intrim/{sdf_name}_f_{F}_dt_{dt}_t_0_{ls.time:.1f}.pkl'\n",
    "joblib.dump((deltas,phis), out_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize intermediate propagation results\n",
    "1. phi values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('bokeh')\n",
    "tsteps= list(phis.keys())\n",
    "hmap = hv.HoloMap({t: hv.Image((ls.xs, ls.ys, phis[t])) for t in tsteps})\n",
    "# hmap.opts(framewise=True, fig_inches=10) # for matplotlib\n",
    "hmap.opts(shared_axes=False) # for bokeh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save animation of propagation with contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('matplotlib')                \n",
    "out = f'../outputs/levelset/{sdf_name}_f_{F}_dt_{dt}_t_0_{ls.time:.1f}' \n",
    "contour_hmap =hv.operation.contours(hmap,levels=5)\n",
    "overlay = hmap * contour_hmap\n",
    "overlay.opts(framewise=True, fig_inches=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.save(hmap.opts(framewise=True), out + '_hmap.gif', fps=1)\n",
    "hv.save(overlay.opts(framewise=True), out+'_overlay.gif', fps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phis in dmap\n",
    "phi_dmap = hv.DynamicMap(lambda t: hv.Image((xs,ys,phis[t])), kdims='t').redim.values(t=tsteps)\n",
    "phi_dmap = phi_dmap.opts(img_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dmap of contours\n",
    "contour_dmap = hv.operation.contours(phi_dmap,levels=10)\n",
    "contour_dmap = contour_dmap.redim.values(t=list(phis.keys())).opts(contour_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. deltas in hv.Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results\n",
    "try: \n",
    "    deltas.pop(0.)\n",
    "except KeyError:\n",
    "    print(\"deltas don't contain time=0 value\")\n",
    "    pass\n",
    "\n",
    "curve = hv.Curve(deltas)\n",
    "dmap_point = hv.DynamicMap(lambda t: hv.Points( [(t, deltas[t])] ),\n",
    "                           kdims='t')\n",
    "dmap_point = dmap_point.redim.values(t=list(deltas.keys()))\n",
    "\n",
    "(curve * dmap_point.opts(color='red', size=5)).redim.label(x='time', y='delta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive simulation\n",
    "hv.extension('bokeh')\n",
    "selected_curve = (curve * dmap_point).redim.values(t=tsteps).redim.label(x='time', y='delta')\n",
    "overlay = ( phi_dmap * contour_dmap + selected_curve )\n",
    "overlay.opts(img_opts, contour_opts).opts(opts.Points(color='red', size=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo:\n",
    "- [x] use Run method \n",
    "- [ ] debug why it's moving up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_levelset_unit_circle(to_save=False):\n",
    "    n_points = 100\n",
    "    xlim = (-2,2)\n",
    "    ylim = (-2,2)\n",
    "    sdf = sdfs.sdUnitCircle\n",
    "    sef_name = 'sdUnitCircle'\n",
    "    \n",
    "    xs = np.linspace(*xlim, n_points)\n",
    "    ys = np.linspace(*ylim, n_points)[::-1]\n",
    "    zz = sdfs.eval_sdf(xs, ys, sdf)\n",
    "    ls = LSEvolver(xs,ys,zz)\n",
    "    \n",
    "    # propagation config\n",
    "    F = 1\n",
    "    dt = 1e-3\n",
    "    maxIter = 300\n",
    "    collect_every = 10\n",
    "    threshold=1e-6\n",
    "    \n",
    "    deltas, phis = ls.run(F, dt, pde_class, threshold=1e-6, maxIter=maxIter, collect_every=collect_every)\n",
    "    \n",
    "    # save result\n",
    "    if to_save:\n",
    "        out_pkl = f'../data/intrim/{sdf_name}_f_{F}_dt_{dt}_t_0_{ls.time:.1f}.pkl'\n",
    "        \n",
    "    return deltas, phis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_levelset_star1(to_save=False):\n",
    "    n_points = 100\n",
    "    xlim = (-2,2)\n",
    "    ylim = (-2,2)\n",
    "    sdf = sdfs.sdStar1\n",
    "    sdf_name = 'sdStar1'\n",
    "    \n",
    "    xs = np.linspace(*xlim, n_points)\n",
    "    ys = np.linspace(*ylim, n_points)[::-1]\n",
    "    zz = sdfs.eval_sdf(xs, ys, sdf)\n",
    "    ls = LSEvolver(xs,ys,zz)\n",
    "    \n",
    "    # propagation config\n",
    "    F = 1\n",
    "    dt = 1e-3\n",
    "    maxIter = 300\n",
    "    collect_every = 10\n",
    "    threshold=1e-6\n",
    "    \n",
    "    deltas, phis = ls.run(F, dt, pde_class, threshold=threshold, maxIter=maxIter, collect_every=collect_every)\n",
    "    \n",
    "    # save result\n",
    "    if to_save:\n",
    "        out_pkl = f'../data/intrim/{sdf_name}_f_{F}_dt_{dt}_t_0_{ls.time:.1f}.pkl'   \n",
    "        \n",
    "    return deltas, phis\n",
    "\n",
    "def test_levelset_star2(to_save=False):\n",
    "    n_points = 100\n",
    "    xlim = (-2,2)\n",
    "    ylim = (-2,2)\n",
    "    \n",
    "    sdf = sdfs.sdStar2\n",
    "    sdf_name = 'sdStar2'\n",
    "    \n",
    "    xs = np.linspace(*xlim, n_points)\n",
    "    ys = np.linspace(*ylim, n_points)[::-1]\n",
    "    zz = sdfs.eval_sdf(xs, ys, sdf)\n",
    "    ls = LSEvolver(xs,ys,zz)\n",
    "    \n",
    "    # propagation config\n",
    "    F = 1\n",
    "    dt = 1e-3\n",
    "    maxIter = 300\n",
    "    collect_every = 10\n",
    "    threshold=1e-6\n",
    "\n",
    "    deltas, phis = ls.run(F, dt, pde_class, threshold=threshold, maxIter=maxIter, collect_every=collect_every)\n",
    "    \n",
    "    # save result\n",
    "    if to_save:\n",
    "        out_pkl = f'../data/intrim/{sdf_name}_f_{F}_dt_{dt}_t_0_{ls.time:.1f}.pkl'\n",
    "    \n",
    "    return deltas, phis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = True\n",
    "\n",
    "unit_circle_result = test_levelset_unit_circle(to_save)\n",
    "unit_star1_result = test_levelset_star1(to_save)\n",
    "unit_star2_result = test_levelset_star2(to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_animation(deltas, phis):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aiviz]",
   "language": "python",
   "name": "conda-env-aiviz-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
