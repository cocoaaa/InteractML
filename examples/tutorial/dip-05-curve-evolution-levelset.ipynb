{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified: Jul 31, 2019\n",
    "\n",
    "# Evolution of curves using SDF\n",
    "\n",
    "- Define a step function that encodes the discrete PDF of the curve evolution \n",
    "- Visualize the contour lines (at zero level)\n",
    "- Active Contour \n",
    "    - satellite images\n",
    "    - biomedical images\n",
    "- Next step: \n",
    "    - agent-based clustering for image segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, time\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.signal import correlate2d\n",
    "import pandas as pd\n",
    "    \n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "p = print\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "import pdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "# Don't generate bytecode\n",
    "sys.dont_write_bytecode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import xarray as xr\n",
    "\n",
    "from holoviews import opts, dim\n",
    "from holoviews.operation.datashader import datashade, shade, dynspread, rasterize\n",
    "from holoviews.streams import Stream, param\n",
    "from holoviews import streams\n",
    "import geoviews as gv\n",
    "import geoviews.feature as gf\n",
    "from geoviews import tile_sources as gvts\n",
    "\n",
    "import panel as pn\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "\n",
    "hv.notebook_extension('bokeh')\n",
    "hv.Dimension.type_formatters[np.datetime64] = '%Y-%m-%d'\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the utils directory to the search path\n",
    "UTILS_DIR = Path('../utils').absolute()\n",
    "assert UTILS_DIR.exists()\n",
    "if str(UTILS_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(UTILS_DIR))\n",
    "    print(f\"Added {str(UTILS_DIR)} to sys.path\")\n",
    "\n",
    "# pp(sys.path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_mro as mro, nprint, timeit\n",
    "import utils\n",
    "\n",
    "import sdfs \n",
    "from vector import Vector as vec\n",
    "from samples import LSTestSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calculus as calc\n",
    "from grid import CartesianGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set visualization options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = 500,500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.defaults(\n",
    "    opts.Image(colorbar=True, active_tools=['wheel_zoom'], tools=['hover']),\n",
    "    opts.Curve(tools=['hover'], active_tools=['wheel_zoom']),\n",
    "    opts.RGB(active_tools=['wheel_zoom'], tools=['hover'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_opts = opts.Image(height=H, width=W, colorbar_position='bottom')\n",
    "vfield_opts = opts.VectorField(width=W, height=H, color='Magnitude',\n",
    "#                                magnitude=dim('Magnitude').norm()*0.2,\n",
    "                               pivot='tip',\n",
    "                               rescale_lengths=True)\n",
    "curve_opts = opts.Points(size=5,width=W, height=H, padding=0.1, \n",
    "#                             xlim=(-10,10), ylim=(-10,10),\n",
    "#                         color=dim('p')*256-50\n",
    "                        )\n",
    "contour_opts = opts.Contours(width=W, height=H, \n",
    "                             colorbar=False, \n",
    "                             tools=['hover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab registered bokeh renderer\n",
    "print(\"Currently available renderers: \", *hv.Store.renderers.keys())\n",
    "renderer = hv.renderer('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Curve Evolution \n",
    "\n",
    "Todo\n",
    "- [ ] Finite Difference method on parametric equations\n",
    "- [ ] Levelset functions\n",
    "    - 2D signed distance functions: [src](https://is.gd/t7p5mk)\n",
    "- [ ] Active contour on satellite images\n",
    "- [ ] Agent-based modelling with specified rules\n",
    "    - satellite image segmentation (~ clustering based on local features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Front Propagation \n",
    "Refer to Equation 4.8 and 4.20\n",
    "\n",
    "1. Spatial gradient computation </br>\n",
    "For stability in computing the spatial gradients, use Eqn. 4.33\n",
    "\n",
    "2. Temporal discretization </br>\n",
    "To propagate the front over time, we neet to update the levelset values over time \n",
    "according to a process. We express the process as a partial differential of the levelset function $\\phi$ wrt time:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\phi}{\\partial t} (t)= L(t, \\phi(t)), ~~~~~ \\phi(t_0) = \\phi^{0}\n",
    "$$\n",
    "\n",
    "where $L$ represents a general function that depends on time stamp $t$ and the levelset function itself.\n",
    "Given $L$ and the initial condition $\\phi_{0}$, our goal is to find $\\phi(t_{1}), \\phi(t_{2})$, ... $\\phi(t_{n})$ This process is called **\"time integration''**, as we are solving the partial differential equation wrt time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the first-order Taylor expansion around $t + \\Delta t$, we derive a \"forward\" Euler time integration equation for discretely sampled levelset:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\phi(t+\\Delta t) &\\approx \\phi(t) + \\Delta t \\frac{\\partial \\phi}{\\partial t}(t) \\\\\n",
    "                 &\\approx \\phi(t) + \\Delta t L(t, \\phi(t))\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equations we have described both in a continous and discretized domain for $\\phi(t)$ hold for any $\\phi$, and is not specificed to a levelset function.  In that respect, a better notation to express this generality, I should have used a symbol that is not $\\phi$, oops. But, we are interested in the levelset functions (in particular a discretly sampled one), so from here on, we will view this general equation from the perspective of time integration for a levelset equation.  That means, $\\phi$ refers to the levelset function, and $L$, which describes how the levelset fucntion changes over time, correpsonds to the speed function $F$ in the fundamental levelset form. Recall this speed function is the speed in direction normal to the levelset function (at all levels).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two ways to view the fundamental levelset formulation\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\phi}{\\partial{t}} &= -\\nabla{\\phi} \\cdot \\vec{V}  \\label{eq:4.7}  \\tag{4.7} \\\\\n",
    "                                  &= -\\lVert \\vec{\\nabla} \\phi \\rVert F(\\vec{x}, \\vec{n}, \\phi, \\dots )\n",
    "                                     \\label{eq:4.8}  \\tag{4.8} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "1. Advection: floating surface in an external vectorfield/flow $\\vec{V}$\n",
    "\n",
    "\n",
    "2. Motion of a front in normal direction according to a given speed $F$ </br>\n",
    "The front propagates in its normal direction with a given speed $F(t, \\phi)$\n",
    "\n",
    "The two views are mathmatically equivalent as can be shown by using the equality that links the external vector field point of view to the levelset domain by linking the way to compute normal vector in both domains:\n",
    "\n",
    "$$\n",
    "\\vec{n}(\\vec{x}) = \\frac{\\vec{\\nabla}\\phi (\\vec{x})}{\\lVert \\vec{\\nabla}\\phi (\\vec{x}) \\rVert}\n",
    "$$\n",
    "\n",
    "where $\\vec{x}$ refers to a point in the embedding space. In 2Dim case (ie. for curve evolution), we can express this point with two Cartian coordinates $(x,y)$:\n",
    "\n",
    "$$\n",
    "\\vec{n}(x,y) = \\frac{\\vec{\\nabla}\\phi (x,y)}{\\lVert \\vec{\\nabla}\\phi (x,y) \\rVert}\n",
    "$$\n",
    "\n",
    "The key point of this equality is that it proves the two ways to view the fundamental levelset form are mathmatically equivalent. Nevertheless, their physical meanings are distinct, and we solve the equations differently when it comes to finding the computational solutions, ie. $\\phi(t_{1}),\\phi(t_{2}), \\dots$.\n",
    "\n",
    "The solution to the first approach (ie. advection) will be implemented in `LSEvolver.advect` method. \n",
    "The solution to the second approach (ie. front's normal motion) will be implemented in `LSEvolver. propagate` method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on to the implementation, let me summaruize the time integration of a discrete levelset function for each perspective. Note that superscipts are used to indicate the time steps.\n",
    "\n",
    "1. Advection\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "             \\frac{\\partial \\phi}{\\partial{t}} &=& -\\nabla{\\phi} \\cdot \\vec{V}  \\label{eq:4.7}  \\tag{4.7} \\\\\n",
    "\\Rightarrow  \\phi^{t + \\Delta t} &=& \\phi^{t} - \\Delta t ( \\vec{\\nabla} \\phi^{t} \\cdot \\vec{V^{t}} ) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "2. Front's normal motion\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\phi}{\\partial{t}} &=& -\\lVert \\vec{\\nabla} \\phi \\rVert F(\\vec{x}, \\vec{n}, \\phi, \\dots )\n",
    "                                     \\label{eq:4.8}  \\tag{4.8} \\\\\n",
    "\\Rightarrow  \\phi^{t+\\Delta t} &=& \\phi^{t} - \\Delta t \\lVert \\vec{\\nabla} \\phi^{t} \\rVert \\cdot F^{t} \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common examples of the speed function ( $F^{t}$)\n",
    "- constant: $F^{t} = 1 ~~ \\forall t$,  where the domain of every $F^{t}$ is $\\{ \\vec{x} \\in \\Gamma(t) \\}$\n",
    "\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\phi^{t+\\Delta t} &=& \\phi^{t} - \\Delta t \\lVert \\vec{\\nabla} \\phi^{t} \\rVert \\cdot 1\n",
    "    \\end{align}\n",
    "    $$\n",
    "    \n",
    "- smoothing motion: $F^{t} = 1-\\alpha \\kappa$ where $\\kappa$ is the curvature of the front\n",
    "    - has an effect of regularizing the front (ie. curve in 2 dim case)\n",
    "    \n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\phi^{t+\\Delta t} &=& \\phi^{t} - \\Delta t \\lVert \\vec{\\nabla} \\phi^{t} \\rVert \\cdot (1-\\alpha \\kappa(\\phi^{t})\n",
    "    \\end{align}\n",
    "    $$\n",
    "    \n",
    "Note $F$ is independent of $t$ in both cases, which means the form of the $F$ stays the same across the entire\n",
    "propagation process. That doesn't mean the exact values at $t_1$ and $t_2$ are the same though. Specifically, this implies that we need to compute $\\kappa$ at each step, based on the current time's $\\phi$ since $\\kappa$ is a function of a levelset which is dynamically evolving over time, ie. $\\phi$ has a dependency on time variable $t$.\n",
    "\n",
    "Another comment worth mentioning here is that the first example of constant speed function $F=1$ and the second case where $F$ depends on the curvature belong to different PDE categories. The first case is known as \"hyperbolic\" which is a case of \"Hamilton-Jacobian equation\", and the second case belongs to \"parabolic\" equation.  The criterion to category them into these different PDE classes is the order of derivatives that $F$ is dependent on. \n",
    "\n",
    "- hyperbolic: $F$ depends on at most order $1$ derivative\n",
    "    - eg: $F=1$, $F=\\lVert \\vec{\\nabla} \\phi^{t} \\rVert$\n",
    "    - the front propagation has a directionality (aka. characteristics of the PDE) </br>\n",
    "    $\\Rightarrow$ we need to be careful which spatial gradient to take (forward or backward)\n",
    "    \n",
    "    \n",
    "- parabolic: $F$ depends on derivatives of order greater than $1$\n",
    "    - eg: $F= \\alpha \\kappa$ \n",
    "    - Information related to the current spatial location ($\\vec{x}$) comes from all directions </br>\n",
    "    $\\Rightarrow$ one way to encompass this trait is to use central difference in computing spatial gradients\n",
    "    \n",
    "![advection-update](../assets/update_advection_bw.jpg)\n",
    "![propagation-update](../assets/update_front_propagation_bw.jpg)\n",
    "\n",
    "\n",
    "We will show how these speed functions affect the front propagation behaviors in laster sections.\n",
    "For now, we are ready to jump into the implementation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Modified: Jul 31, 2019 \n",
    "## todo:\n",
    "est: ~~30mins~~ 3days?....?\n",
    "- [x] check i,j -> c,r conversion\n",
    "- [ ] incorporate Grid as a data storage (self.grid) of LevelSet class\n",
    "- [x] get a list of points from holoviews polydraw\n",
    "- [ ] make a list of line segments from the point list\n",
    "- [ ] for each line segment, make Line2d object and get polygon for the band box\n",
    "- [ ] collect the band bbox points into all list, also \n",
    "- [ ] show in holoview with the linesegments and its bands\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "class LSEvolver(CartesianGrid):\n",
    "    \"\"\"\n",
    "    EvolvingLS: A levelSet evolution according to an initial-valued problem given by a PDE\n",
    "    \n",
    "    Args:\n",
    "    - F (callable): takes a LevelSet object and time index and returns a np array \n",
    "    with the same shape as the levelset's grid\n",
    "    \"\"\"\n",
    "    def __init__(self, xs, ys, data=None, t=0):\n",
    "        super().__init__(xs, ys, data)\n",
    "        \n",
    "        self.time = t #current time\n",
    "        self.delta = np.inf # average change of LS function values between consecutive time stamps\n",
    "            \n",
    "    def run(self, F, dt, pde_class, threshold=1e-3, maxIter=1e4):\n",
    "        count = 0\n",
    "        deltas = []\n",
    "        phis = {}\n",
    "        while self.delta > threshold:\n",
    "            if count > maxIter: \n",
    "                print(\"MaxIter reached: \", count)\n",
    "                break\n",
    "            self.propagate(F,dt,pde_class)\n",
    "            deltas.append(self.delta)\n",
    "            count += 1\n",
    "            if count%1000:\n",
    "                phis[self.time] = self.data\n",
    "        print(f\"Ran for {count} steps, for {self.time} periods\")\n",
    "        print(f\"\\taverage delta phi: {self.delta}\")\n",
    "        return deltas, phis\n",
    "\n",
    "    def propagate(self, F, dt, pde_class):\n",
    "        \"\"\"\n",
    "        Equation 4.8 and 4.20\n",
    "        1. Spatial gradient computation\n",
    "        For stability in computing the spatial gradients, use Eqn. 4.33\n",
    "        \n",
    "        2. Temporal discretization\n",
    "        To propagate the front over time, we neet to update the levelset values over time \n",
    "        according to a process. We express the process as a partial differential of the levelset \n",
    "        function (\\phi) wrt time:\n",
    "        \n",
    "        \\frac\n",
    "        \n",
    "        Our goal is to find \\phi(t1), \\phi(t2), ... given a initial \\phi(t0)\n",
    "        equatation\n",
    "        This process is called \"time integration\" \n",
    "        \n",
    "        Args:\n",
    "        - pde_class (str): 'hyperbolic', 'parabolic'\n",
    "            * (1) if F depends on at most order 1 derivatives of the levelset function phi \n",
    "            wrt space and time, the information propagation has a specific direction \n",
    "            (ie. \"characteristics\"), and we need to be careful about which gradient to \n",
    "            take -- backward, forward.  In this case, the levelset equation is 'hyperbolic', \n",
    "            which is a subclass of Hamilton-Jacobian equation. \n",
    "            \n",
    "            * (2) if F depends on derivatives of order >= 2 (eg. F = alpha*curvature),\n",
    "            then the information propagates from all directions, and we can use the \n",
    "            central finite difference method to compute the spatial gradients.\n",
    "        \"\"\"\n",
    "        if dt > min(self.dx, self.dy):\n",
    "            #todo: print error but then make dt smaller smartly\n",
    "            raise ValueError('dt should be smaller than x and y sample resolutions: ', dt)\n",
    "                \n",
    "        assert pde_class in ['hyperbolic','parabolic'], \\\n",
    "        f\"pde_class must be either 1 or 2: {pde_class}\"\n",
    "        \n",
    "        if pde_class == 'hyperbolic':\n",
    "            dxb, dxf, dyb, dyf = self.get_diff1_bf()\n",
    "            debug = (\n",
    "                hv.Image(self.data, label='phi') + hv.Image([])\n",
    "                + hv.Image(dxb, label='dx back') + hv.Image(dxf, label='dx forward')\n",
    "                + hv.Image(dyb, label='dy back') + hv.Image(dyf, label='dy forward')\n",
    "            ).cols(2)\n",
    "            display(debug)\n",
    "\n",
    "            S = np.sign(F)\n",
    "            dx = np.maximum(S*dxb, -S*dxf)\n",
    "            dy = np.maximum(S*dyb, -S*dyf)\n",
    "\n",
    "            dmag = np.sqrt(dx**2 + dy**2)\n",
    "            \n",
    "        else :#pde_class == 'parabolic':\n",
    "            dx,dy = self.get_diff1_central()\n",
    "            dmag = comput_mag(dx,dy)# todo\n",
    "        \n",
    "        \n",
    "        # update phi\n",
    "        dphi = dt* dmag * F\n",
    "        self.delta = dphi.sum() / dphi.size\n",
    "        self.data -= dphi \n",
    "        \n",
    "        # update time\n",
    "        self.time += dt\n",
    "        \n",
    "    def advect(self, V, dt):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - V (ndarray of shape (w,h,2)): containing x and y component of the vector field\n",
    "        - dt (float): time step size\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def reinit(self, method='sweep'):\n",
    "        \"\"\"\n",
    "        Reset current phi values (in self.data) to satisfy Eikonal equality\n",
    "        in Eqn. 4.12\n",
    "        \n",
    "        - method \n",
    "            - 'pde': solve eqn. 4.37 with current phi data, until steady state\n",
    "            - 'fmm': fast marching method\n",
    "            - 'sweep' (default): paper [88]\n",
    "            - 'exact': paper [64]\n",
    "            \n",
    "            Default is 'sweep'\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def get_diff1_bf(self, switch=True):\n",
    "        dxb, dxf, dyb, dyf = calc.diff1_bf(self.data, switch)\n",
    "        return dxb/self.dx, dxf/self.dx, dyb/self.dy, dyf/self.dy\n",
    "    \n",
    "    def get_diff1_central(self):\n",
    "        dx, dy= calc.diff1_central(self.data)\n",
    "        return dx/(2*self.dx), dy/(2*self.dy)\n",
    "    \n",
    "    def get_curvature(self):\n",
    "        return curvature(self.data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test LSEvolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aiviz]",
   "language": "python",
   "name": "conda-env-aiviz-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
